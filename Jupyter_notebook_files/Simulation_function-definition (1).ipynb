{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98e1d4ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import time as timing\n",
    "import os\n",
    "#from Edited_Photons_for_any_TTBIN import Photons\n",
    "import random\n",
    "import math\n",
    "from numba import jit\n",
    "from numba import njit\n",
    "from scipy.stats import poisson\n",
    "from IPython.display import clear_output\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "def coherence_length(wavelength_nm, delta_lambda_nm):\n",
    "    # Convert wavelength from nm to meters\n",
    "    wavelength_m = wavelength_nm * 1e-9\n",
    "    \n",
    "    # Convert delta_lambda from nm to meters\n",
    "    delta_lambda_m = delta_lambda_nm * 1e-9\n",
    "    \n",
    "    # Calculate coherence length\n",
    "    coherence_length_m = (wavelength_m ** 2) / (np.pi * delta_lambda_m)\n",
    "    \n",
    "    # Convert coherence length from meters to nm\n",
    "    coherence_length_nm = coherence_length_m * 1e9\n",
    "    \n",
    "    return coherence_length_nm\n",
    "\n",
    "\n",
    "def calculate_histograms(arrival_times):\n",
    "    all_histograms = np.zeros((10,))  # Initialize an array to accumulate histograms\n",
    "    for i, arrival_time in enumerate(arrival_times):\n",
    "        time_differences = np.abs(arrival_times - arrival_time)  # Calculate time differences\n",
    "        histogram, _ = np.histogram(time_differences, bins=10, range=(0, np.max(time_differences)))\n",
    "        all_histograms += histogram  # Accumulate histograms\n",
    "    return all_histograms\n",
    "\n",
    "#this function assigns photons to channels the arrival time array has been created \n",
    "@jit(nopython=True)\n",
    "def process_photon_arr(photon_arr, p1, random_number, buffer_size):\n",
    "    photon_number = photon_arr.shape[0]\n",
    "    for buffer in range(1, int(photon_number / buffer_size) + 1):\n",
    "        upper_index = buffer * buffer_size\n",
    "        lower_index = (buffer - 1) * buffer_size\n",
    "\n",
    "        temp_arr = p1[lower_index:upper_index].reshape(-1, 1)\n",
    "\n",
    "        mask = random_number[lower_index:upper_index] > temp_arr\n",
    "\n",
    "        temp_photon_arr = photon_arr[lower_index:upper_index]\n",
    "        mask = np.squeeze(mask)\n",
    "\n",
    "        temp_photon_arr[mask, 0] = 2\n",
    "        photon_arr[lower_index:upper_index] = temp_photon_arr\n",
    "\n",
    "    return photon_arr\n",
    "\n",
    "#this function will assign frequencies to photons given two specific frequencies\n",
    "@jit\n",
    "def assign_freq_for_binaryfreq(photon_number,sequence_length, ensamble_size, freq_array,top_freq, bot_freq):\n",
    "    for j in range(0,photon_number,int(sequence_length)):\n",
    "        binomial_number = np.random.binomial( ensamble_size, .5, size=1)\n",
    "        index0 = j\n",
    "        index1 = int(j+sequence_length)\n",
    "        \n",
    "        prob = binomial_number/ ensamble_size\n",
    "    \n",
    "        for k in range(len(freq_array[index0:index1])):\n",
    "            #change every other value to be 600 or 650c\n",
    "            random_number = random.uniform(0,1)\n",
    "         \n",
    "            if random_number > prob:\n",
    "                freq_array[index0+k] = bot_freq\n",
    "            else:\n",
    "                freq_array[index0+k] = top_freq\n",
    "'''Old assignment function'''\n",
    "def assign_gaussian_frequency_old(photon_number, sequence_length, ensamble_size, freq_array, top_freq ,bot_freq, std_dev):\n",
    "    for j in range(0,photon_number,int(sequence_length)):\n",
    "        index0 = j\n",
    "        index1 = int(j+sequence_length)\n",
    "        binomial_number = np.random.binomial( ensamble_size, .5, size=1)\n",
    "        prob = binomial_number/ ensamble_size\n",
    "        \n",
    "        \n",
    "        random_number = random.uniform(0,1)\n",
    "      \n",
    "        if random_number > prob:\n",
    "            freq_array[index0:index1] = np.random.normal(top_freq, std_dev, size=int(sequence_length))\n",
    "        else:\n",
    "            freq_array[index0:index1] = np.random.normal(bot_freq, std_dev, size=int(sequence_length))\n",
    "            \n",
    "\n",
    "\n",
    "@jit\n",
    "def assign_gaussian_frequency(photon_number, sequence_length, ensemble_size, freq_array, top_freq, bot_freq, std_dev):\n",
    "    for j in range(0, photon_number - sequence_length + 1, sequence_length):\n",
    "        index0 = j\n",
    "        index1 = j + sequence_length\n",
    "        binomial_number = np.random.binomial(ensemble_size, 0.5, size=1)\n",
    "        prob = binomial_number / ensemble_size\n",
    "        random_number = random.uniform(0, 1)\n",
    "        if random_number > prob:\n",
    "            freq_array[index0:index1] = np.random.normal(top_freq, std_dev, size=sequence_length)\n",
    "        else:\n",
    "            freq_array[index0:index1] = np.random.normal(bot_freq, std_dev, size=sequence_length)\n",
    "    \n",
    "    # Handle remaining photons\n",
    "    remaining_photons = photon_number % sequence_length\n",
    "    if remaining_photons > 0:\n",
    "        index0 = photon_number - remaining_photons\n",
    "        index1 = photon_number\n",
    "        binomial_number = np.random.binomial(ensemble_size, 0.5, size=1)\n",
    "        prob = binomial_number / ensemble_size\n",
    "        random_number = random.uniform(0, 1)\n",
    "        if random_number > prob:\n",
    "            freq_array[index0:index1] = np.random.normal(top_freq, std_dev, size=remaining_photons)\n",
    "        else:\n",
    "            freq_array[index0:index1] = np.random.normal(bot_freq, std_dev, size=remaining_photons)\n",
    "\n",
    "\n",
    "def assign_gaussian_frequency_v2(sequence_length, total_time, time_array, photon_number, expected_oscillations):\n",
    "    time_freq_array = np.random.choice([top_freq, bot_freq], size=int(expected_oscillations))\n",
    "  \n",
    "    \n",
    "    # Compute indices for frequency assignment\n",
    "    indices = (time_array // (total_time * 1e12 / expected_oscillations)) % len(time_freq_array)\n",
    "    \n",
    "    # Use indices to assign frequencies with random noise\n",
    "    freq_array = np.random.normal(time_freq_array[indices.astype(int)], std_dev)\n",
    "    \n",
    "    return freq_array\n",
    "\n",
    "\n",
    "      \n",
    "\n",
    "#@jit\n",
    "def assign_frequency_soft_switching(detector_resolution,probability_per_bin, total_time, time_array, photon_number, expected_oscillations,bottom_freq,top_freq,linewidth, lineshape = 'lorentzian'):\n",
    "    switching_arr = np.zeros((2,int(expected_oscillations)))\n",
    "    \n",
    "    switching_arr[0,:] = np.sort(np.random.uniform(0,total_time*1e12, size=int(expected_oscillations)))\n",
    "    switching_arr[1,:] = np.random.choice(np.array([top_freq, bottom_freq]), size=int(expected_oscillations))\n",
    "\n",
    "    indices = np.searchsorted(switching_arr[0, :], time_array, side='right')%len(switching_arr) \n",
    " \n",
    "    freq_arr = np.zeros(photon_number)\n",
    "    # Draw from a Gaussian distribution for each center frequency\n",
    "    for i in range(photon_number):\n",
    "        # Get the center frequency corresponding to the index\n",
    "        index = indices[i]\n",
    "     \n",
    "        center_frequency = switching_arr[1, index]\n",
    "        if lineshape == 'gaussian':\n",
    "            # Draw from a Gaussian distribution with center frequency as mean and be sure that the linewidth parameter is std_dev and not HWHM like for lorentzian\n",
    "            freq_arr[i] = np.random.normal(center_frequency, linewidth)\n",
    "        if lineshape == 'lorentzian':\n",
    "            #or a lorentzian \n",
    "            freq_arr[i] = center_frequency + linewidth*np.random.standard_cauchy()\n",
    "        else: \n",
    "            print('================================')\n",
    "            print('wrong lineshape parameter')\n",
    "            print('================================')\n",
    "    return freq_arr\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "'''\n",
    "these two functions have different perfomances but essentially do the same thing. It is better to use the first with large photon numner usually\n",
    "and better to use the second with small photon number and or small bin size. I would test them to see what works best for your combination of detector \n",
    "resolution and photon number. the second usually works better If you arent at or near the array memory limit for time_arr\n",
    "'''\n",
    "#@jit(nopython=True)\n",
    "def simulate_arrival_time(time_arr, PPS, total_time, detector_resolution, probability_per_bin):\n",
    "    for i in range(1, PPS * total_time):\n",
    "        passed_bins = 1\n",
    "        while time_arr[i] == 0:\n",
    "            random_number = random.random()\n",
    "\n",
    "            if probability_per_bin > random_number:\n",
    "                time_arr[i] = time_arr[i - 1] + passed_bins * detector_resolution\n",
    "            else:\n",
    "                passed_bins += 1\n",
    "                \n",
    "#@jit(nopython=True)\n",
    "def simulate_arrival_time_alternate(time_arr, photon_number, total_time, detector_resolution, number_of_bins):\n",
    "    for i in range(1, photon_number):\n",
    "        arrival_bin = random.randint(0, int(number_of_bins))\n",
    "     \n",
    "        time_arr[i] = arrival_bin*detector_resolution\n",
    "    time_arr_sorted = np.sort(time_arr)\n",
    "    return time_arr_sorted\n",
    "\n",
    "def arrival_time_vectorized(photon_number,total_time):\n",
    "    time_arr = np.random.uniform(0, total_time*1e12, size=int(photon_number))\n",
    "    return np.sort(time_arr)\n",
    "\n",
    "def simulate_arrival_time_gamma(photon_number,probability_per_bin,detector_resolution):\n",
    "    arrival_times = np.random.gamma(shape=1, scale=1/probability_per_bin, size=int(photon_number))\n",
    "    arrival_times = np.cumsum(arrival_times) *detector_resolution\n",
    "    return arrival_times\n",
    "\n",
    "\n",
    "#writes stage positions in an exponential manner\n",
    "def exp_spacing_position(number_of_pos, final_pos, stage_position):\n",
    "    \n",
    "    x = final_pos**(1/number_of_pos)\n",
    "    \n",
    "    for i in range(0,number_of_pos+1):\n",
    "        new_pos = x**i\n",
    "        stage_position.append(new_pos)\n",
    "#writes stage positions in a linear manner\n",
    "def linear_spacing_position(number_of_pos, final_pos, stage_position):\n",
    "    x = final_pos/number_of_pos\n",
    "    for i in range(number_of_pos):\n",
    "        a = i\n",
    "        new_pos = x*a\n",
    "        stage_position.append(new_pos)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "efef6362",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Gaussian functions f(x) and g(x)\n",
    "def gaussian(x, A, mu, sigma):\n",
    "    return A * np.exp(-0.5 * ((x - mu) / sigma)**2)\n",
    "\n",
    "def lorenzian(x, x0, gamma, A):\n",
    "    return A * (gamma / ((x - x0) ** 2 + gamma ** 2) / np.pi)\n",
    "\n",
    "'''\n",
    "yet to see if both of these functions work the same in the curve fitting, they should \n",
    "'''\n",
    "#def gaussian(x, A, mu, sigma):\n",
    "  #  return A * np.exp(-(x - mu)**2 / (2 * sigma**2))\n",
    "\n",
    "\n",
    "def calculate_convolution_gaussian(top_freq, bot_freq,std_dev, plot = False):\n",
    "    A = 1\n",
    "    mu_f = 0\n",
    "    mu_g = np.abs(top_freq-bot_freq)\n",
    "\n",
    "    x_min = -5\n",
    "    x_max = 5\n",
    "    delta_x = .01\n",
    "    x_values = np.arange(x_min, x_max, delta_x)\n",
    "\n",
    "    # Compute the values of f(x) and g(x)\n",
    "    f_x = gaussian(x_values, A, mu_f, std_dev)\n",
    "    g_x = gaussian(x_values, A, mu_g, std_dev)\n",
    "    g_x_neg = gaussian(x_values, A, -1*mu_g, std_dev)\n",
    "    # Compute the cross-correlation\n",
    "    cross_corr_result = np.correlate(f_x, f_x, mode='same') * delta_x\n",
    "    dif_cross_corr_result = np.correlate(f_x, 2*f_x+g_x+g_x_neg, mode='same') * delta_x\n",
    "    \n",
    "\n",
    "    popt, pcov = curve_fit(gaussian, x_values, cross_corr_result/max(cross_corr_result), p0=[1, 0, 1])\n",
    "    dif_popt, dif_pcov = curve_fit(gaussian, x_values, dif_cross_corr_result/max(dif_cross_corr_result), p0=[1, 0, 1])\n",
    "    \n",
    "    # Extract parameters of the fitted Gaussian\n",
    "    A_fit, mu_fit, sigma_fit = popt\n",
    "    \n",
    "    dif_A_fit, dif_mu_fit, dif_sigma_fit = dif_popt\n",
    "\n",
    "    # Compute FWHM\n",
    "    FWHM1 = 2 * np.sqrt(2 * np.log(2)) * sigma_fit\n",
    "    dif_FWHM = 2 * np.sqrt(2 * np.log(2)) * dif_sigma_fit\n",
    "\n",
    "    # Compute standard deviation\n",
    "    std_deviation1 = sigma_fit\n",
    "    if plot:\n",
    "        # Plot the original cross-correlation and the fitted Gaussian\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.plot(x_values, cross_corr_result/max(cross_corr_result), label='Cross-correlation', color='blue')\n",
    "        plt.plot(x_values, dif_cross_corr_result/max(dif_cross_corr_result), label='dif_Cross-correlation', color='purple')\n",
    "        \n",
    "        plt.plot(x_values, gaussian(x_values, *popt), label='Fitted Gaussian', color='red', linestyle='--')\n",
    "        plt.plot(x_values, gaussian(x_values, *dif_popt), label='dif_Fitted Gaussian', color='green', linestyle='--')\n",
    "        plt.title('Cross-correlation and Fitted Gaussian')\n",
    "        plt.xlabel('x')\n",
    "        plt.ylabel('Cross-correlation')\n",
    "        plt.legend()\n",
    "        \n",
    "        plt.show()\n",
    "\n",
    "        print('% undiffused is',(100*(FWHM1/dif_FWHM)))\n",
    "    return ((FWHM1/dif_FWHM))\n",
    "   \n",
    "def calculate_convolution_lorentzian(top_freq, bot_freq, gamma, plot=False):\n",
    "    A = 1\n",
    "    mu_f = 0\n",
    "    mu_g = np.abs(top_freq - bot_freq)\n",
    "    print(f'{mu_g}')\n",
    "    x_min = -5\n",
    "    x_max = 5\n",
    "    delta_x = .001\n",
    "    x_values = np.arange(x_min, x_max, delta_x)\n",
    "    \n",
    "    # Compute the values of f(x) and g(x)\n",
    "    f_x = lorenzian(x_values, mu_f, gamma, A)\n",
    "    g_x = lorenzian(x_values, mu_g, gamma, A)\n",
    "    g_x_neg = lorenzian(x_values, -1 * mu_g, gamma, A)\n",
    "    \n",
    "    \n",
    "    # Compute the cross-correlation\n",
    "    cross_corr_result = np.correlate(f_x, f_x, mode='same') * delta_x\n",
    "    dif_cross_corr_result = np.correlate(f_x, 2 * f_x + g_x + g_x_neg, mode='same') * delta_x\n",
    "\n",
    "    popt, pcov = curve_fit(lorenzian, x_values, cross_corr_result / max(cross_corr_result), p0=[0, 1, 1])\n",
    "    dif_popt, dif_pcov = curve_fit(lorenzian, x_values, dif_cross_corr_result / max(dif_cross_corr_result), p0=[0, 1, 1])\n",
    "    \n",
    "    # Extract parameters of the fitted Lorentzian\n",
    "    x0_fit, gamma_fit, A_fit = popt\n",
    "    dif_x0_fit, dif_gamma_fit, dif_A_fit = dif_popt\n",
    "\n",
    "    # Compute FWHM\n",
    "    FWHM1 = 2 * gamma_fit\n",
    "    dif_FWHM = 2 * dif_gamma_fit\n",
    "\n",
    "    if plot:\n",
    "        # Plot the original cross-correlation and the fitted Lorentzian\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.plot(x_values, cross_corr_result / max(cross_corr_result), label='Cross-correlation', color='blue')\n",
    "        plt.plot(x_values, dif_cross_corr_result / max(dif_cross_corr_result), label='dif_Cross-correlation', color='purple')\n",
    "\n",
    "        plt.plot(x_values, lorenzian(x_values, *popt), label='Fitted Lorentzian', color='red', linestyle='--')\n",
    "        plt.plot(x_values, lorenzian(x_values, *dif_popt), label='dif_Fitted Lorentzian', color='green', linestyle='--')\n",
    "        plt.title('Cross-correlation and Fitted Lorentzian')\n",
    "        plt.xlabel('x')\n",
    "        plt.ylabel('Cross-correlation')\n",
    "        plt.legend()\n",
    "        plt.xlim(-2,2)\n",
    "        plt.show()\n",
    "      \n",
    "        print('% undiffused is', (100 * (FWHM1 / dif_FWHM)))\n",
    "    \n",
    "    return FWHM1 / dif_FWHM\n",
    "    \n",
    "\n",
    "def run_simulation(directory, top_freq, bot_freq, std_dev, ensamble_size, photons_per_emitter,total_time ,number_of_pos ,detector_resolution = 1e2,\n",
    "                   switching_time = 1e8):\n",
    "    pos_file_name = directory + os.sep +'posFile.pos'\n",
    "    pcfs_file_name = directory + os.sep +'position.pcfslog'\n",
    "    pos_file = open(pos_file_name,'w')\n",
    "    pcfs_log_file = open(pcfs_file_name, 'w')\n",
    "    PPS = int(ensamble_size*photons_per_emitter)\n",
    "    expected_oscillations = int(total_time*1e12/switching_time)\n",
    "    # Calculate coherence length\n",
    "    coherence_length_result = coherence_length(bot_freq, std_dev)\n",
    "    print(\"Coherence Length:\", coherence_length_result, \"nm\") \n",
    "    #choose center stage positions in nm as path length differences \n",
    "    stage_position = []\n",
    "    \n",
    "    final_pos = coherence_length_result #in nm. 1e8 is the largest possible stage pos but dont increase sim beyond 7e5 in practicality\n",
    "    linear_spacing_position(number_of_pos, final_pos,stage_position)\n",
    "    \n",
    "    counter = 0\n",
    "    for i in stage_position:\n",
    "        #photon_number = int(PPS*total_time)\n",
    "        photon_number =int(np.random.poisson(int(PPS*total_time)))\n",
    "\n",
    "        projected_time_start = timing.time()\n",
    "        counter +=1\n",
    "        print(f'stage position {counter} completed')\n",
    "        file_name = f'pos {int(i)}'\n",
    "        \n",
    "          # Calculate probability of finding a photon in a detector bin\n",
    "        probability_per_bin = (PPS / 1e12) * detector_resolution\n",
    "        number_of_bins = total_time*1e12/detector_resolution\n",
    "        start1 = timing.time()\n",
    "        time_arr = simulate_arrival_time_gamma(photon_number,probability_per_bin,detector_resolution)\n",
    "        end1 = timing.time()\n",
    "        print(f'time to simulate arrival times {end1-start1}')\n",
    "\n",
    "\n",
    "        start4 = timing.time()\n",
    "        freq_array = assign_frequency_soft_switching(detector_resolution,probability_per_bin, total_time, time_arr, photon_number, expected_oscillations, bot_freq, top_freq, std_dev)\n",
    "        end4 = timing.time()\n",
    "        print(f'time to assign freqq {end4-start4}')\n",
    "        center_stage_position = i\n",
    "        #amplitude in nm /2 this is from center to peak \n",
    "        dither_amplitude = 1200\n",
    "        #period in  picoseconds\n",
    "        dither_time_period =int(1e12)\n",
    "        time_between_stage_steps = 1e6\n",
    "        \n",
    "   \n",
    "        #all data for each photon stored in an array, first column is channel, second is arrival time, fourth is frequency, third is a place holder if the sim will expand to add relative time to a pulse\n",
    "        photon_arr = np.zeros((photon_number, 4))\n",
    "        #set the 4th column to be photon color\n",
    "        photon_arr[:,3]= freq_array\n",
    "        #set the first column to be channel 1\n",
    "        photon_arr[:,0] =1\n",
    "        photon_arr[:,1] = time_arr\n",
    "        #create dither waveform \n",
    "        #make sure the dither period is divisible by 4 to work with nice round numbers\n",
    "        dither_waveform = np.zeros(int(dither_time_period/time_between_stage_steps))\n",
    "\n",
    "        dither_waveform[:int(dither_time_period/(4*time_between_stage_steps))] = np.linspace(center_stage_position , dither_amplitude+center_stage_position,int(dither_time_period/(4*time_between_stage_steps)))\n",
    "        dither_waveform[int(dither_time_period/(4*time_between_stage_steps)):int(3*dither_time_period/(4*time_between_stage_steps))] = np.linspace(dither_amplitude+center_stage_position , center_stage_position-dither_amplitude, int(dither_time_period/(2*time_between_stage_steps)))\n",
    "        dither_waveform[int(3*dither_time_period/(4*time_between_stage_steps)):] = np.linspace(center_stage_position-dither_amplitude , center_stage_position,  int(dither_time_period/(4*time_between_stage_steps)))\n",
    "        #Find where we are in the dither given absolute time\n",
    "        relative_dither_time = photon_arr[:,1] % dither_time_period\n",
    "        stage_pos = np.zeros(photon_number)\n",
    "         # Convert relative_dither_time to indices directly\n",
    "        indices = (relative_dither_time / time_between_stage_steps).astype(int)\n",
    "        # Use array indexing to assign values to stage_pos\n",
    "        stage_pos = dither_waveform[indices]\n",
    "        #based on interference contstruct a probability of going to one detector or the other, this also serves to make the detectors anticorrelated in phase\n",
    "        p1 = .5 +.5*np.cos(4*np.pi*stage_pos[:]/photon_arr[:,3])\n",
    "      \n",
    "        random_number = np.random.rand(photon_number, 1)\n",
    "\n",
    "        start2 = timing.time()\n",
    "\n",
    "        # Reshape p1 array to match the shape of random_number\n",
    "        p1_reshaped = p1.reshape(-1, 1)\n",
    "\n",
    "        # Use vectorized comparison to create mask\n",
    "        mask = random_number > p1_reshaped\n",
    "\n",
    "        # Convert mask to boolean array\n",
    "        mask = np.squeeze(mask)\n",
    "\n",
    "        # Modify photon_arr in-place using boolean indexing\n",
    "        photon_arr[mask, 0] = 2\n",
    "\n",
    "        end2 = timing.time()\n",
    "        print(f'time to make photons array {end2 - start2}')\n",
    "\n",
    "        #write positions to file as nm\n",
    "        value = str(i*1e-6)\n",
    "\n",
    "        pos_file.write(value + \"\\n\")\n",
    "        pcfs_log_file.write(value + \"\\n\")\n",
    "        \n",
    "        photons_mimic = photon_arr[:,:2]\n",
    "        photons_mimic = photons_mimic.flatten()\n",
    "        \n",
    "        #write photons file in binary\n",
    "        fout = open(directory +os.sep + file_name + '.photons', 'wb')\n",
    "        \n",
    "        photons_mimic.astype(np.uint64).tofile(fout)\n",
    "        fout.close()\n",
    "        \n",
    "        projected_time_end = timing.time()\n",
    "        total_for_one_loop = projected_time_end - projected_time_start\n",
    "        total_time_proj = total_for_one_loop * number_of_pos\n",
    "        time_left = total_time_proj - total_for_one_loop*counter\n",
    "        print(f'total time to complete is {int(total_time_proj/60)}mins and the total time left is {int(time_left/60)}mins')\n",
    "        \n",
    "        \n",
    "        \n",
    "    pos_file.close() \n",
    "    pcfs_log_file.close()\n",
    "    \n",
    "def convert_wn_to_wl(reighliegh_wavelength,raman_wavenumber,linewidth_cm, freq_jump_cm):\n",
    "    raman_wavelength = 1e7/(1e7/reighliegh_wavelength-raman_wavenumber)\n",
    "    #cm -1 to nm conversion \n",
    "    #for single conversion s\n",
    "\n",
    "    raman_wavelength = 1e7/(1e7/reighliegh_wavelength-raman_wavenumber)\n",
    "\n",
    "    #compute the nm shift for inverse cm shifts\n",
    "    center_peak1 = raman_wavenumber\n",
    "    upper_end1 = center_peak1+linewidth_cm/2\n",
    "    lower_end1 = center_peak1-linewidth_cm/2\n",
    "    upper_nm1 = 1e7/(1e7/reighliegh_wavelength-upper_end1)\n",
    "    lower_nm1= 1e7/(1e7/reighliegh_wavelength-lower_end1)\n",
    "\n",
    "    #linewidth in nm \n",
    "    linewidth_nm = (upper_nm1-lower_nm1)/2\n",
    "\n",
    "    #compute the nm shift for inverse cm shifts\n",
    " \n",
    "    center_peak = raman_wavenumber\n",
    "    upper_end = center_peak+freq_jump_cm\n",
    "    lower_end = center_peak\n",
    "    upper_nm = 1e7/(1e7/reighliegh_wavelength-upper_end)\n",
    "    lower_nm = 1e7/(1e7/reighliegh_wavelength-lower_end)\n",
    "\n",
    "    #linewidth in nm \n",
    "    nm_shift = upper_nm-lower_nm\n",
    "\n",
    "    return (raman_wavelength, nm_shift, linewidth_nm)\n",
    "\n",
    "raman_wavelength, shift, linewidth = convert_wn_to_wl(reighliegh_wavelength = 633,raman_wavenumber = 810 ,linewidth_cm = 1.5, freq_jump_cm = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "75686a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%run jupyter_photons_code_FI.ipynb   \n",
    "%run jupyter_pcfs_code_FI.ipynb\n",
    "\n",
    "primary_directory = '/global/scratch/projects/co_utzatgroup/ccobbbruno/24_11_01/'\n",
    "\n",
    "\n",
    "\n",
    "ensamble_size = 1\n",
    "#photons per emitter per second\n",
    "photons_per_emitter =1e5\n",
    "# Define time of simulation in s\n",
    "total_time =int(10)\n",
    "detector_resolution = 1e2\n",
    "#the number of cycles you expect the frequency to go through in ps\n",
    "switching_time = 1e9\n",
    "number_of_pos = 10\n",
    "\n",
    "raman_wavelength, shift, linewidth = convert_wn_to_wl(reighliegh_wavelength = 633, raman_wavenumber = 810 ,linewidth_cm = 4, freq_jump_cm = 6)\n",
    "dif_array = [shift]\n",
    "\n",
    "collective_fwhm_arr = []\n",
    "std_dev = linewidth\n",
    "top_freq = raman_wavelength\n",
    "print(dif_array,std_dev)\n",
    "pcfs_instances = {}\n",
    "for dif in dif_array:\n",
    "    directory = os.path.join(primary_directory, f'{dif:.2f}nm_wavelength_difference')\n",
    "    \n",
    "    # Check if the directory already exists\n",
    "    if not os.path.exists(directory):\n",
    "        # If not, create the directory\n",
    "        os.makedirs(directory)\n",
    "        print(f\"Created directory: {directory}\")\n",
    "    else:\n",
    "        print(f\"Directory already exists: {directory}\")\n",
    "        \n",
    "    \n",
    "    bot_freq = float(raman_wavelength + dif)\n",
    "    \n",
    "    run_simulation(directory, top_freq, bot_freq, std_dev, ensamble_size, photons_per_emitter,total_time ,number_of_pos)\n",
    "    \n",
    "    pcfs_instance_name = f\"pcfs_{dif:.2f}\"\n",
    "    pcfs_instances[pcfs_instance_name] = PCFS(directory, 2, simulation=True)\n",
    "    pcfs_instances[pcfs_instance_name].get_intensity_correlations((1e1, 1e11), 3)\n",
    "    pcfs_instances[pcfs_instance_name].get_blinking_corrected_PCFS()\n",
    "    pcfs_instances[pcfs_instance_name].get_splev_mirror_spec_corr(0, 0, fit_interferogram = True)\n",
    "    pcfs_instances[pcfs_instance_name].plot_spectral_diffusion([1e2, 1e6, 1e9], -4)\n",
    "    pcfs_instances[pcfs_instance_name].plot_splev_spec_corr([1e7, 1e9], (-2.5, 2.5))\n",
    "    #for i,tau in enumerate(pcfs_instances[pcfs_instance_name].tau):\n",
    "       # plt.plot(pcfs_instances[pcfs_instance_name].blinking_corrected_PCFS_interferogram[i, :])\n",
    "       # plt.show()\n",
    "        \n",
    "    calculate_convolution_lorentzian(top_freq, bot_freq,std_dev, plot = True)\n",
    "\n",
    "    fwhm_arr = []\n",
    "    for i in range(len(pcfs_instances[pcfs_instance_name].tau)):\n",
    "        y = pcfs_instances[pcfs_instance_name].splev_spec_corr['spectral_corr'][i,:]/max(pcfs_instances[pcfs_instance_name].splev_spec_corr['spectral_corr'][i,:])\n",
    "        x = pcfs_instances[pcfs_instance_name].splev_spec_corr['zeta']\n",
    "        try:\n",
    "            params, covariance = curve_fit(lorenzian, x, y)\n",
    "        except RuntimeError:\n",
    "            fwhm_arr.append(0)\n",
    "        else:\n",
    "            #for lorenzian\n",
    "            fwhm = 2 * params[1] \n",
    "            #for gaussian\n",
    "            #fwhm = 2 * np.sqrt(2 * np.log(2)) * params[2]\n",
    "            fwhm_arr.append(fwhm)\n",
    "            #plt.plot(x, y, 'bo', label='Data')\n",
    "            #plt.plot(x, lorenzian(x, *params), 'r-', label='Fit')\n",
    "            #plt.legend()\n",
    "\n",
    "           # plt.show()\n",
    "\n",
    "    plt.scatter(pcfs_instances[pcfs_instance_name].tau,fwhm_arr, label='Scatter Plot on Log Scales')\n",
    "    plt.xscale('log')\n",
    "    #plt.xlim(1e4,1e11)\n",
    "    #plt.ylim(.5,1.1)\n",
    "    plt.show()\n",
    "    \n",
    "    print(bot_freq)\n",
    "    print(top_freq)\n",
    "    total_end = timing.time()\n",
    "    #print(f'total run time: {total_end-total_start}')\n",
    "    collective_fwhm_arr.append(fwhm_arr)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
