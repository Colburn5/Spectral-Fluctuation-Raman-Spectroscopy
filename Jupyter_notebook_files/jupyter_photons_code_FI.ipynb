{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e07f15d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Python for analysis of photon stream data from the Picoqunt GmbH Hydraharp and t3 data from Boris's labview program for the Swabian TimeTagger.\n",
    "\n",
    "Adapted from photons.m V5.0 @ HENDRIK UTZAT, KATIE SHULENBERGER, BORIS SPOKOYNY, TIMOTHY SINCLAIR (10/29/2017)\n",
    "\n",
    "Weiwei Sun, July, 2019\n",
    "\n",
    "\n",
    "Update Sept. 2020, t2 data from swabian timetagger20 output files can be converted to .photons files and use functions in this class. (may need to rewrite main file though)\n",
    "\n",
    "\n",
    "Update Feb. 2023, Colburn Cobb-Bruno, code adapted to use new file formats .ttbin provided by the lastest swabian timetagger \n",
    "'''\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import time as timing\n",
    "import os, struct, scipy, warnings\n",
    "from numba import jit\n",
    "import matplotlib.pyplot as plt \n",
    "#import TimeTagger\n",
    "warnings.filterwarnings('ignore')\n",
    "from array import array\n",
    "import numba\n",
    "from time import sleep\n",
    "\n",
    "class Photons:\n",
    "    \n",
    "    \n",
    "    def __init__(self, file_path, measurement_mode, simulation = False, file_name = None, memory_limit = 1):\n",
    "        \n",
    "\n",
    "        \n",
    "       # self.header_size = None # size of headers in bytes\n",
    "        self.header = None # dictionary for header information\n",
    "        self.memory_limit = memory_limit\n",
    "        self.buffer_size = int(self.memory_limit * 1024 * 1024 / 8) # how many uint64 can be read at once\n",
    "        self.cross_corr = None\n",
    "        self.auto_corr = None     #  dictionary to store the correlations\n",
    "        self.datatype = np.uint64 \n",
    "        self.simulaiton = simulation\n",
    "       \n",
    "        self.ch0 = None\n",
    "        self.ch1 = None\n",
    "        self.ch2 = None\n",
    "        self.ch3 = None\n",
    "        self.ch4= None\n",
    "   \n",
    "        # extract photon stream file info\n",
    "        if simulation:\n",
    "            self.path_str = os.path.split(file_path)[0]\n",
    "            self.file_name = file_name\n",
    "            self.header = {}\n",
    "    \n",
    "        else:\n",
    "            print('Only simulations allowed on savio')\n",
    "            '''\n",
    "            self.filereader = TimeTagger.FileReader(file_path)\n",
    "            self.file_path = file_path\n",
    "            self.path_str = os.path.split(file_path)[0] #gets file path\n",
    "            self.file_name = os.path.split(file_path)[1].split('.')[0] #gets name i.e. File is dot8.1.ttbin; returns dot8\n",
    "            self.file_ext = os.path.split(file_path)[1].split('.')[1] # gets run i.e. File is dot8.1.ttbin; returns dot1\n",
    "            self.header = self.filereader.getConfiguration()\n",
    "            '''\n",
    "        self.g2 = None\n",
    "        self.all_photon_data = None\n",
    "        self.all_photon_data_no_OF = None\n",
    "        self.intensity_counts = None\n",
    "        self.sync_channel = None\n",
    "        \n",
    "       \n",
    "        self.header['MeasurementMode'] = measurement_mode\n",
    "        print('========================================')\n",
    "        print('Photon class created')\n",
    "        print('========================================')\n",
    "        \n",
    "       \n",
    "   \n",
    "    \n",
    "        '''\n",
    "        -----------------------------------------------------------------------------------\n",
    "        This function puts all the data about channel, timestamp, and overflow information\n",
    "        into an array to be written to binary \n",
    "        it also gets the header information containing the state of the .ttbin file at time of measurement. \n",
    "        you need to specify the measurementmode yourself\n",
    "        -----------------------------------------------------------------------------------\n",
    "        '''\n",
    "\n",
    "        #n_events here is the size of the buffer to work with in order to speed up computational time\n",
    "    \n",
    " \n",
    "    def get_arival_data_and_header(self, manual_resolution=0, n_events=1000000):\n",
    "        if self.simulaiton == False:\n",
    "            print('Only simulations allowed on savio')\n",
    "            '''\n",
    "            start_time = timing.time()\n",
    "            \n",
    "                \n",
    "            inputs = self.header['inputs']\n",
    "            \n",
    "            if 'resolution rms' in self.header:\n",
    "                resolution_rms = [d['resolution rms'] for d in inputs]\n",
    "                self.header['Resolution'] = np.mean(resolution_rms)\n",
    "            else:\n",
    "                self.header['Resolution'] = manual_resolution\n",
    "                \n",
    "            filereader = TimeTagger.FileReader(self.file_path)\n",
    "            \n",
    "            # create empty arrays using np.empty()\n",
    "            Complete_Channel_Array = np.empty(0, dtype=np.int64)\n",
    "            Complete_Arrival_Time = np.empty(0, dtype=np.uint64)\n",
    "            Complete_Overflow_Array = np.empty(0, dtype=np.uint8)\n",
    "            Complete_Missed_Events = np.empty(0, dtype=np.uint32)\n",
    "            data_list = [Complete_Channel_Array, Complete_Arrival_Time, Complete_Overflow_Array, Complete_Missed_Events]\n",
    "        \n",
    "            while filereader.hasData():\n",
    "                data = filereader.getData(n_events=n_events)\n",
    "                channel = data.getChannels()\n",
    "                timestamps = data.getTimestamps()\n",
    "                overflow_types = data.getEventTypes()\n",
    "                missed_events = data.getMissedEvents()\n",
    "                \n",
    "                for i, arr in enumerate(data_list):\n",
    "                    data_list[i] = np.concatenate((arr, eval(f\"{'channel' if i == 0 else 'timestamps' if i == 1 else 'overflow_types' if i == 2 else 'missed_events'}\")))\n",
    "            \n",
    "    \n",
    "            All_Photon_Data = np.concatenate([arr[np.newaxis, :] for arr in data_list], axis=0)\n",
    "            \n",
    "         \n",
    "            self.all_photon_data = All_Photon_Data\n",
    "            self.all_photon_data_no_OF = self.all_photon_data[:2, :]\n",
    "           \n",
    "            del filereader\n",
    "            \n",
    "            end_time = timing.time()\n",
    "            total_time = end_time - start_time\n",
    "            print('Time elapsed for data header function is %4f s' % total_time)\n",
    "            '''\n",
    "            \n",
    "    '''\n",
    "    -----------------------------------------------------------------------------------\n",
    "    this funciton writes all the data into an array with a single row\n",
    "    for a file that you have specified to be t3 and using the channel the pulse enters,\n",
    "    it will rewrite the file into an array that goes like [ch, t, tau, ch, t, tau...] t=absolute tau=time after pulse\n",
    "    for t2 data it writes the data into an array that goes like [ch, t, ch, t...]\n",
    "    if it is t2 data you can have the sync_channel anything\n",
    "    ====================================================================================\n",
    "    IMPORTANT:\n",
    "        for t3 data I do not know what units self.header['SyncRate'] should be in as it \n",
    "        was given for all picoquant files but swabian has no such information tied to \n",
    "        their files. will be important to test if using t3 data\n",
    "    ====================================================================================\n",
    "    -----------------------------------------------------------------------------------\n",
    "    '''\n",
    "    def write_total_data_to_file(self, sync_channel = 1):\n",
    "       if self.simulaiton == False:\n",
    "        \n",
    "            time_start = timing.time()\n",
    "          \n",
    "            \n",
    "            fout = open(self.path_str +os.sep + self.file_name + '.photons', 'wb')\n",
    "            \n",
    "            relative_photon_data = np.array(self.all_photon_data_no_OF)  # if for some reason the array isnt in chronological order np.array([list(x) for x in zip(*sorted(zip(*self.all_photon_data_no_OF), key=lambda x: x[1]))])\n",
    "            self.sync_channel = sync_channel\n",
    "            \n",
    "            if self.header['MeasurementMode'] == 2:\n",
    "          \n",
    "                flattened_array = np.zeros(self.all_photon_data_no_OF.shape[1]*2)\n",
    "                for i in range(self.all_photon_data_no_OF.shape[1]):\n",
    "                    flattened_array[2*i] = self.all_photon_data_no_OF[0][i]\n",
    "                    flattened_array[2*i+1] = self.all_photon_data_no_OF[1][i]\n",
    "                \n",
    "      \n",
    "                flattened_array.astype(self.datatype).tofile(fout)\n",
    "             \n",
    "                \n",
    "             \n",
    "            elif self.header['MeasurementMode'] == 3:\n",
    "               \n",
    "                \n",
    "                mask = self.all_photon_data_no_OF[0,:] == sync_channel\n",
    "                pulse_channels = self.all_photon_data_no_OF[:, mask]\n",
    "                time_differences = np.diff(pulse_channels[1,:])\n",
    "                self.header['SyncRate'] = 1/(np.mean(time_differences))\n",
    "                \n",
    "                   \n",
    "                mask = relative_photon_data[0,:] == sync_channel\n",
    "                diffs = np.diff(np.where(np.append(False, mask)))[0]\n",
    "                starts = np.where(mask)[0]\n",
    "                \n",
    "                for start, diff in zip(starts, diffs):\n",
    "                    relative_photon_data[1, start : start + diff] -= relative_photon_data[1, start]\n",
    "             \n",
    "                t3_type_array = np.delete(np.concatenate((self.all_photon_data_no_OF, relative_photon_data),axis = 0),2,0)\n",
    "            #print (t3_type_array[:,:20])\n",
    "            \n",
    "                mask = t3_type_array[0,:] != sync_channel\n",
    "                t3_type_array_no_pulse= t3_type_array[:,mask]\n",
    "           # print(t3_type_array_no_pulse)\n",
    "                flattened_array = np.zeros(t3_type_array_no_pulse.shape[1]*3)\n",
    "            \n",
    "                for i in range(t3_type_array_no_pulse.shape[1]):\n",
    "                   flattened_array[3*i] = t3_type_array_no_pulse[0][i]\n",
    "                   flattened_array[3*i+1] = t3_type_array_no_pulse[1][i]\n",
    "                   flattened_array[3*i+2] = t3_type_array_no_pulse[2][i]\n",
    "           \n",
    "            flattened_array.astype(self.datatype).tofile(fout)\n",
    "            \n",
    "            fout.close()\n",
    "            \n",
    "           \n",
    "            time_end = timing.time()\n",
    "            total_time = time_end - time_start\n",
    "            print('Time elapsed to write to .photons file is %4f s' % total_time)\n",
    "\n",
    "\n",
    "    '''\n",
    "    ---------------------------------------------------\n",
    "    this function below will create write all the photon timestamstamps into a binary file while making all the \n",
    "    channels =0\n",
    "    use this as a check while also uncommenting all the relevant print statements in other functions\n",
    "    \n",
    "    photons1= Photons(file_name, 34)\n",
    "    photons1.get_header_info(2)\n",
    "\n",
    "    photons1.get_arival_data()\n",
    "    a=photons1.all_photon_data_no_OF[1,-20:-1]\n",
    "    for i in a.tolist():\n",
    "        print(\"{:.10f}\".format(i))\n",
    "    print(len(photons1.all_photon_data_no_OF[0]))\n",
    "    photons1.write_total_data_to_file()\n",
    "\n",
    "    photons1.write_photons_to_one_channel('', '') is an example of what you would call\n",
    "    ---------------------------------------------------\n",
    "    '''\n",
    "\n",
    "    def write_photons_to_one_channel(self, file_in, file_out):\n",
    "\n",
    "        time_start = timing.time()\n",
    "        counts = self.buffer_size * self.header['MeasurementMode']\n",
    "        fout_file = self.path_str + os.sep+ file_out + '.photons'\n",
    "        fin_file = self.path_str +os.sep+ file_in + '.photons'\n",
    "        fin = open(fin_file, 'rb')\n",
    "        fout = open(fout_file, 'wb')\n",
    "       \n",
    "        while 1:\n",
    "           batch = np.fromfile(fin, dtype=self.datatype, count = counts)\n",
    "           batch[::self.header['MeasurementMode']] = 0 # set the channel number to be 0\n",
    "           batch.tofile(fout)\n",
    "    \n",
    "           if len(batch) < counts:\n",
    "               break\n",
    "    \n",
    "        fout.close()\n",
    "        fin.close()\n",
    "        time_end = timing.time()\n",
    "        total_time = time_end - time_start\n",
    "        print('========================================')\n",
    "        print('Photon records written to %s.photons' % file_out,)\n",
    "        print('Time elapsed is %4f s' % total_time)\n",
    "        print('========================================')\n",
    "        \n",
    "        \n",
    "       \n",
    "        '''\n",
    "        ---------------------------------------------------------------------------------\n",
    "        This function writes the data in the .photons file to each respective channel\n",
    "        photons_to_channel('','',# of channels(optional))\n",
    "        for t3 mode, the the moment the laser sync channel is removed so it will write an empty file \n",
    "        for which ever channel the laser pulses were entering\n",
    "        ---------------------------------------------------------------------------------\n",
    "        '''\n",
    "\n",
    "    def photons_to_channel(self, file_in, file_out, n_channel = 4):\n",
    "\n",
    "        time_start = timing.time()\n",
    "        counts = self.buffer_size * self.header['MeasurementMode']\n",
    "        fin_file = self.path_str +file_in + '.photons'\n",
    "        fin = open(fin_file, 'rb')\n",
    "        fout_file = [self.path_str + file_out + '_ch' + str(i) + '.photons' for i in range(n_channel)]\n",
    "        fout = [open(file, 'wb') for file in fout_file]\n",
    "\n",
    "        while 1:\n",
    "            batch = np.fromfile(fin, dtype=self.datatype, count = counts)\n",
    "            lbatch = len(batch)//self.header['MeasurementMode']\n",
    "            batch.shape = lbatch, self.header['MeasurementMode']\n",
    "            for i in range(n_channel):\n",
    "                batch[batch[:, 0] == i].tofile(fout[i])\n",
    "\n",
    "            if lbatch < self.buffer_size:\n",
    "                break\n",
    "\n",
    "        fin.close()\n",
    "        for i in range(n_channel):\n",
    "            fout[i].close()\n",
    "        time_end = timing.time()\n",
    "        total_time = time_end - time_start\n",
    "        print('Total time elapsed is %4f s' % total_time)\n",
    "\n",
    "\n",
    "        \n",
    "        '''\n",
    "       This function sorts photon data according to photon arrival time.\n",
    "       For t2 data the time in ps is the absolute arrival time of the photons.\n",
    "       For t3 data the time is relative to the sync pulse.\n",
    "       A new .photons file is written containing the photons detected within tau_window: [lower_tau, upper_tau] in ps.\n",
    "       =============================================================================\n",
    "       IMPORTANT: \n",
    "           I have not really tried to fix this function but it doesnt seem \n",
    "       to work yet. I have gotten around the issue by using the np.sort function\n",
    "       in any methods that require the photon stream to be in order which works well but it \n",
    "       may have limitations I havent found yet\n",
    "       ==============================================================================\n",
    "       '''\n",
    "       \n",
    "    def arrival_time_sorting(self, file_in, file_out, tau_window):\n",
    "          \n",
    "        time_start = timing.time()\n",
    "        # counts = self.buffer_size * self.header['MeasurementMode']\n",
    "        fin_file = self.path_str +file_in + '.photons'\n",
    "        fin = open(fin_file, 'rb')\n",
    "        fout_file = self.path_str + file_out + '.photons'\n",
    "        fout = open(fout_file, 'wb')\n",
    "        \n",
    "        while 1:\n",
    "            batch = np.fromfile(fin, dtype=self.datatype, count = counts)\n",
    "            lbatch = len(batch)//self.header['MeasurementMode']\n",
    "            batch.shape = lbatch, self.header['MeasurementMode']\n",
    "            ind_lower = batch[:, -1] > tau_window[0]\n",
    "            ind_upper = batch[:, -1] <= tau_window[1]\n",
    "            batch[ind_lower * ind_upper].tofile(fout)\n",
    "        \n",
    "            if lbatch < self.buffer_size:\n",
    "                break\n",
    "        \n",
    "        fin.close()\n",
    "        fout.close()\n",
    "        time_end = timing.time()\n",
    "        total_time = time_end - time_start\n",
    "        print('Total time elapsed is %4f s' % total_time)\n",
    "\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    This function compiles and stores the intensity trace as a property of the photons class: self.intensity_counts.\n",
    "\n",
    "    Two *args must be given, in the order of:\n",
    "        file_in: filename of the .photons file without ending.\n",
    "        bin_width: width of the bin for intensity compilation - ps for t2 data; number of pulses for t3 data.\n",
    "    \n",
    "    for plotting self.intensity_counts['trace'] is a matrix where each column is corresponds to each channel\n",
    "    '''\n",
    "           \n",
    "    def get_intensity_trace(self, file_in, bin_width):\n",
    "\n",
    "        # time_start = timing.time()\n",
    "        \n",
    "        fin_file = self.path_str +os.sep+ file_in + '.photons'\n",
    "        fin = open(fin_file, 'rb')\n",
    "        photons_records = np.fromfile(fin, dtype=self.datatype)\n",
    "        fin.close()\n",
    "\n",
    "        self.intensity_counts = {}\n",
    "        length_photons = len(photons_records) // self.header['MeasurementMode']\n",
    "        photons_records.shape = length_photons, self.header['MeasurementMode']\n",
    "        n_bins = int(photons_records[-1,1] // bin_width)\n",
    "        bins = np.arange(0.5, n_bins+1.5) * bin_width\n",
    "        time_vec = np.arange(1, n_bins+1) * bin_width\n",
    "        photon_trace = np.zeros((n_bins, 4)) # store the histogram\n",
    "\n",
    "\n",
    "\n",
    "        for i in range(4):\n",
    "            temp = photons_records[photons_records[:,0] == i,1]\n",
    "            photon_trace[:, i] = np.histogram(temp, bins = bins)[0]\n",
    "\n",
    "        self.intensity_counts['time'] = time_vec\n",
    "        self.intensity_counts['bin_width'] = bin_width\n",
    "        self.intensity_counts['trace'] = photon_trace\n",
    "\n",
    "        # time_end = timing.time()\n",
    "        # print('Total time elapsed is %4f s' % (time_end - time_start))\n",
    "\n",
    "    \n",
    "  \n",
    "    '''\n",
    "    This function histograms the lifetime of a .ht3 file with a given resolution.The histogram is stored as a property of the photons class: self.histo_lifetime.\n",
    "    The given resolution should be a multiple of the original resolution used for the measurement. For instance, if the measurement resolution was 64 ps, then\n",
    "    the resolution to form the histogram of the photon-arrival records could be 128, 256, 384, or 512 ps ...\n",
    "    '''  \n",
    "    \n",
    "    \n",
    "    def get_lifetime_histogram(self,file_in, resolution):\n",
    "\n",
    "        if self.header['MeasurementMode'] == 2:\n",
    "            print('Only fot t3 data!')\n",
    "            return False\n",
    "        if resolution % int(self.header['Resolution']) != 0:\n",
    "            print('The given resolution must be a multiple of the original resolution!\\n')\n",
    "            print('Check obj.header[\\'Resolution\\'].')\n",
    "            return False\n",
    "\n",
    "        time_start = timing.time()\n",
    "        self.histo_lifetime = {}\n",
    "\n",
    "        fin_file = self.path_str + file_in + '.photons'\n",
    "        fin = open(fin_file, 'rb')\n",
    "\n",
    "        # initializations\n",
    "        rep_time = 1e12/self.header['SyncRate'] # in ps\n",
    "        n_bins = int(rep_time//resolution)\n",
    "        bins = np.arange(0.5, n_bins+1.5) * resolution\n",
    "        time = np.arange(1,n_bins+1) * resolution\n",
    "        hist_counts = np.zeros(n_bins)\n",
    "\n",
    "        counts = self.buffer_size * self.header['MeasurementMode']\n",
    "        while 1:\n",
    "            batch = np.fromfile(fin, dtype=self.datatype, count = counts)\n",
    "            histo = np.histogram(batch[2::3], bins = bins)\n",
    "            hist_counts +=  histo[0]\n",
    "\n",
    "            if len(batch) < counts:\n",
    "                break\n",
    "        # This could be used to test whether we need batch operations\n",
    "        # photons_records = np.fromfile(fin, dtype = self.datatype)\n",
    "        # hist_counts = np.histogram(photons_records[2::3], bins = bins)[0]\n",
    "\n",
    "        fin.close()\n",
    "\n",
    "        if self.header['Equip'] == 'TT':\n",
    "            time = rep_time - time\n",
    "\n",
    "        self.histo_lifetime['Time'] = time\n",
    "        self.histo_lifetime['Lifetime'] = hist_counts\n",
    "        self.histo_lifetime['Resolution'] = resolution\n",
    "\n",
    "        plt.semilogy(time/1000, hist_counts)\n",
    "        plt.xlabel('Time [ns]')\n",
    "        plt.ylabel('Counts')\n",
    "        plt.title('Lifetime histogram with resolution ' + str(resolution) + ' ps')\n",
    "        plt.show()\n",
    "\n",
    "        time_end = timing.time()\n",
    "        total_time = time_end - time_start\n",
    "        print('Total time elapsed is %4f s' % total_time)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    '''\n",
    "    ============================================================================================\n",
    "    Photon correlation\n",
    "    ============================================================================================\n",
    "    '''\n",
    "\n",
    "    '''\n",
    "    Adapted from Boris Spokoyny's code.\n",
    "    This function allows to correlate the photon-stream on a log timescale. The photon correlation is stored as a property of the photons class: self.cross_corr or self.auto_corr.\n",
    "\n",
    "    file_in: file ID of the photons-file to correlate\n",
    "    correlations: 'cross_corr' or 'auto_corr'.\n",
    "    channels: Hydraharp channels to be correlated. e.g. [0,1] for cross-correlation of channels 0 and 1.\n",
    "    time_bounds: upper and lower limit for the correlation. In ps for T2, in pulses for T3.\n",
    "    lag_precision: Number of correlation points between time-spacings of log(2). Must be integers larger than 1.\n",
    "    lag_offset: offset in ps or pulses between the channels.\n",
    "\n",
    "    This algorithm computes the cross-correlation between ch0 and ch1 variables.\n",
    "    For T2 data, ch0 and ch1 correspond to absolute photon arrival times.\n",
    "    For T3 data, ch0 and ch1 should correspond to the photon arrival sync pulse number.\n",
    "    start_time and stop_time for T2 data should be in time units of the photon arrival times, and for T3 data should be in units of sync pulses.\n",
    "\n",
    "    The correlation lags are log(2) spaced with coarseness # of lags per cascade, i.e. if start_time = 1; stop_time = 50; coarseness = 4; the lag bins will be [1, 2, 3, 4;  6, 8, 10, 12;  16, 20, 24, 28;  36, 44 ]. If coarseness = 2, the lag bins become [1, 2;  4, 6;  10, 14;  22,30;  46].\n",
    "    The algorithm works by taking each photon arrival time and counting the number of photons that are lag bins away. For example say our lag bin edges are [1, 2, 4, 6, 10, 14]\n",
    "            Time Slot: 1   2   3   4   5   6   7   8   9   10  11  12  13  14  15\n",
    "            Photon     1   1   0   0   1   1   0   1   1   0   1   0   0   0   1\n",
    "            1st Photon ^\n",
    "            Lag bins   |   |       |       |               |               |\n",
    "            # photons    1     0       2           2                1\n",
    "            2nd Photon     ^\n",
    "            Lag bins       |   |       |       |               |               |\n",
    "            # photons        0     1       1           3               1\n",
    "            3rd Photon                 ^\n",
    "            Lag bins                   |   |       |       |               |               |\n",
    "            # photons                    1     2       1           1               1\n",
    "\n",
    "            etc..\n",
    "    The cross-correlation is the sum of all the photons for each bin, i.e. for the three runs above we get [2, 3, 4, 6, 3].\n",
    "  \n",
    "    This function counts the number of photons in the photon stream bins according to a prescription from Ted Laurence: Fast flexible algirthm for calculating photon correlation, Optics Letters, 31, 829, 2006\n",
    "    \n",
    "    \n",
    "    photon_corr give the G2 function which is the same as the normalized cross correlation\n",
    "    '''\n",
    "    \n",
    "       \n",
    "        \n",
    "    @jit\n",
    "    def photons_in_bins(self, ch0, ch1, lag_bin_edges, offset_lag):\n",
    "        num_ch0 = len(ch0)\n",
    "        num_ch1 = len(ch1)\n",
    "        n_edges = len(lag_bin_edges)\n",
    "        low_inds = np.zeros(n_edges, dtype = int)\n",
    "        max_inds = np.zeros(n_edges, dtype = int)\n",
    "        acf = np.zeros(n_edges-1)\n",
    "    \n",
    "        low_inds[0] = 1\n",
    "        for phot_ind in range(num_ch0):\n",
    "            bin_edges = ch0[phot_ind] + lag_bin_edges + offset_lag\n",
    "    \n",
    "            for k in range(n_edges-1):\n",
    "                while low_inds[k] < num_ch1 and ch1[low_inds[k]] < bin_edges[k]:\n",
    "                    low_inds[k] += 1\n",
    "    \n",
    "                while max_inds[k] < num_ch1 and ch1[max_inds[k]] <= bin_edges[k+1]:\n",
    "                    max_inds[k] += 1\n",
    "    \n",
    "                low_inds[k+1] = max_inds[k]\n",
    "                acf[k] += max_inds[k] - low_inds[k]\n",
    "    \n",
    "        return acf\n",
    "            \n",
    "      \n",
    "       \n",
    "    \n",
    "    def photon_corr(self, file_in, correlations, channels, time_bounds, lag_precision, lag_offset = 0):\n",
    "\n",
    "        time_start = timing.time()\n",
    "\n",
    "        fin_file = self.path_str +os.sep+file_in + '.photons'\n",
    "        \n",
    "        fin = open(fin_file, 'rb')\n",
    "        photons_records = np.fromfile(fin, dtype=self.datatype)\n",
    "        length_photons = len(photons_records) // self.header['MeasurementMode']\n",
    "        photons_records.shape = length_photons, self.header['MeasurementMode']\n",
    "        fin.close()\n",
    "       \n",
    "        # split into channels\n",
    "        ch0_u = photons_records[photons_records[:,0] == channels[0], 1] # ch0 syncs\n",
    "        ch1_u = photons_records[photons_records[:,0] == channels[1], 1] # ch1 syncs\n",
    "  \n",
    "        ch0 = np.sort(ch0_u)\n",
    "        ch1 = np.sort(ch1_u)        \n",
    "   \n",
    "        start_time, stop_time = time_bounds\n",
    "\n",
    "        '''create log 2 spaced lags'''\n",
    "        cascade_end = int(np.log2(stop_time)) # cascades are collections of lags  with equal bin spacing 2^cascade\n",
    "        nper_cascade =  lag_precision # number of equal\n",
    "        a = np.array([2**i for i in range(1,cascade_end+1)])\n",
    "        b = np.ones(nper_cascade)\n",
    "        division_factor = np.kron(a,b)\n",
    "        lag_bin_edges = np.cumsum(division_factor/2)\n",
    "        lags = (lag_bin_edges[:-1] + lag_bin_edges[1:]) * 0.5\n",
    "\n",
    "        # find the bin region\n",
    "        start_bin = np.argmin(np.abs(lag_bin_edges - start_time))\n",
    "        stop_bin = np.argmin(np.abs(lag_bin_edges - stop_time))\n",
    "        lag_bin_edges = lag_bin_edges[start_bin:stop_bin+1] # bins\n",
    "        lags = lags[start_bin+1:stop_bin+1] # center of the bins\n",
    "        division_factor = division_factor[start_bin+1:stop_bin+1] # normalization factor\n",
    "\n",
    "\n",
    "        # counters etc for normalization\n",
    "        ch0_min = np.inf\n",
    "        \n",
    "        ch1_min = np.inf # minimum time tag\n",
    "        ch0_count = len(ch0)\n",
    "        ch1_count = len(ch1) # photon numbers in each channel\n",
    "   \n",
    "        ch0_min = min(ch0_min, min(ch0))\n",
    "        ch1_min = min(ch1_min, min(ch1))\n",
    "\n",
    "        '''correlating '''\n",
    "        tic = timing.time()\n",
    "        print('Correlating data...\\n')\n",
    "\n",
    "        corr = self.photons_in_bins(ch0, ch1, lag_bin_edges, lag_offset)\n",
    "\n",
    "        # normalization\n",
    "        ch0_max = max(ch0)\n",
    "        ch1_max = max(ch1)\n",
    "        tag_range = max(ch1_max, ch0_max) - min(ch1_min, ch0_min) # range of tags in the entire dataset\n",
    "\n",
    "        corr_div = corr/division_factor\n",
    "        corr_norm = 2 * corr_div * tag_range**2 / (tag_range - lags)  / (ch0_count * ch1_count) # * ch0_max in boris' code. changed to tag_range\n",
    "\n",
    "        print('Done\\n')\n",
    "        toc = timing.time()\n",
    "        print('Time elapsed during correlating is %4f s' % (toc-tic))\n",
    "\n",
    "        # store in property\n",
    "        if self.header['MeasurementMode'] == 3:\n",
    "            sync_period = 1e12/self.header['SyncRate']\n",
    "            lags = lags * sync_period\n",
    "\n",
    "        if 'cross' in correlations:\n",
    "            self.cross_corr = {}\n",
    "            self.cross_corr['lags'] = lags\n",
    "            self.cross_corr['corr_norm'] = corr_norm\n",
    "        elif 'auto' in correlations:\n",
    "            self.auto_corr = {}\n",
    "            self.auto_corr['lags'] = lags\n",
    "            self.auto_corr['corr_norm'] = corr_norm\n",
    "\n",
    "\n",
    "        time_end = timing.time()\n",
    "        print('Total time elapsed is %4f s' % (time_end - time_start))\n",
    "\n",
    "\n",
    "        '''\n",
    "        This function calculates g2 for t3 data.\n",
    "        file_in and channels are the same as photon_corr.\n",
    "        time_range is the maximum time we're interested in, in ps.\n",
    "        n_bins are the number of bins for correlation.\n",
    "        '''\n",
    "\n",
    "    def get_g2(self, file_in, channels, time_range, n_bins):\n",
    "    \n",
    "        if self.header['MeasurementMode'] == 2:\n",
    "            print('Only for t3 data!')\n",
    "            return False\n",
    "    \n",
    "        time_start = timing.time()\n",
    "    \n",
    "        fin_file = self.path_str +file_in + '.photons'\n",
    "        fin = open(fin_file, 'rb')\n",
    "        photons_records = np.fromfile(fin, dtype=self.datatype)\n",
    "        length_photons = len(photons_records) // 3\n",
    "        photons_records.shape = length_photons, 3\n",
    "        fin.close()\n",
    "       \n",
    "        # split into channels\n",
    "        pulse = 1e12 / self.header['SyncRate']\n",
    "        ch0 = photons_records[photons_records[:,0] == channels[0], 2] + photons_records[photons_records[:,0] == channels[0], 1] * pulse# ch0 time\n",
    "        \n",
    "        ch1 = photons_records[photons_records[:,0] == channels[1], 2] + photons_records[photons_records[:,0] == channels[1], 1] * pulse# ch1 time\n",
    "        \n",
    "        \n",
    "        \n",
    "        # use linear spaced bins for g2 calculation\n",
    "        bin_width = time_range // n_bins\n",
    "        lag_bin_edges = np.arange(0, time_range + 2 * bin_width, bin_width)\n",
    "        lags = np.hstack((-lag_bin_edges[-2::-1], lag_bin_edges[1:]))\n",
    "        lag_bin_edges = lags- bin_width/2\n",
    "    \n",
    "    \n",
    "        '''correlating '''\n",
    "        tic = timing.time()\n",
    "        print('Correlating data...\\n')\n",
    "    \n",
    "        corr = self.photons_in_bins(ch0, ch1, lag_bin_edges, 0)\n",
    "        #print(corr)\n",
    "       \n",
    "        # correct for offset\n",
    "        n_ind = pulse // bin_width\n",
    "        print(corr[n_bins:int(n_bins+1.5*n_ind)])\n",
    "        ind_pulse_1 = np.argmax(corr[n_bins:int(n_bins+1.5*n_ind)]) # find the index of the first pulse\n",
    "        offset = pulse - lags[ind_pulse_1+n_bins] # correct for offset\n",
    "    \n",
    "        print('Done\\n')\n",
    "        toc = timing.time()\n",
    "        print('Time elapsed during correlating is %4f s' % (toc-tic))\n",
    "        self.g2 = {}\n",
    "        self.g2['lags'] = (lags[:-1] + offset) / 1e3 # in ns\n",
    "        self.g2['g2'] = corr\n",
    "    \n",
    "        plt.plot(self.g2['lags'], self.g2['g2'], '-o', markersize = 1)\n",
    "        plt.ylabel('Event counts')\n",
    "        plt.xlabel('Pulse separation [ns]')\n",
    "        \n",
    "        plt.show()\n",
    "    \n",
    "        time_end = timing.time()\n",
    "        print('Total time elapsed is %4f s' % (time_end - time_start))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
