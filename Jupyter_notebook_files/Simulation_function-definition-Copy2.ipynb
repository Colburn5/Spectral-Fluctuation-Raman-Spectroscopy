{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98e1d4ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import time as timing\n",
    "import os\n",
    "#from Edited_Photons_for_any_TTBIN import Photons\n",
    "import random\n",
    "import math\n",
    "from numba import jit\n",
    "from numba import njit\n",
    "from scipy.stats import poisson\n",
    "from IPython.display import clear_output\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "def coherence_length(wavelength_nm, delta_lambda_nm):\n",
    "    # Convert wavelength from nm to meters\n",
    "    wavelength_m = wavelength_nm * 1e-9\n",
    "    \n",
    "    # Convert delta_lambda from nm to meters\n",
    "    delta_lambda_m = delta_lambda_nm * 1e-9\n",
    "    \n",
    "    # Calculate coherence length\n",
    "    coherence_length_m = (wavelength_m ** 2) / (np.pi * delta_lambda_m)\n",
    "    \n",
    "    # Convert coherence length from meters to nm\n",
    "    coherence_length_nm = coherence_length_m * 1e9\n",
    "    \n",
    "    return coherence_length_nm\n",
    "\n",
    "\n",
    "def calculate_histograms(arrival_times):\n",
    "    all_histograms = np.zeros((10,))  # Initialize an array to accumulate histograms\n",
    "    for i, arrival_time in enumerate(arrival_times):\n",
    "        time_differences = np.abs(arrival_times - arrival_time)  # Calculate time differences\n",
    "        histogram, _ = np.histogram(time_differences, bins=10, range=(0, np.max(time_differences)))\n",
    "        all_histograms += histogram  # Accumulate histograms\n",
    "    return all_histograms\n",
    "\n",
    "#this function assigns photons to channels the arrival time array has been created \n",
    "@jit(nopython=True)\n",
    "def process_photon_arr(photon_arr, p1, random_number, buffer_size):\n",
    "    photon_number = photon_arr.shape[0]\n",
    "    for buffer in range(1, int(photon_number / buffer_size) + 1):\n",
    "        upper_index = buffer * buffer_size\n",
    "        lower_index = (buffer - 1) * buffer_size\n",
    "\n",
    "        temp_arr = p1[lower_index:upper_index].reshape(-1, 1)\n",
    "\n",
    "        mask = random_number[lower_index:upper_index] > temp_arr\n",
    "\n",
    "        temp_photon_arr = photon_arr[lower_index:upper_index]\n",
    "        mask = np.squeeze(mask)\n",
    "\n",
    "        temp_photon_arr[mask, 0] = 2\n",
    "        photon_arr[lower_index:upper_index] = temp_photon_arr\n",
    "\n",
    "    return photon_arr\n",
    "\n",
    "\n",
    "def assign_gaussian_frequency_soft_switching_under_envelope(detector_resolution,probability_per_bin,total_time, time_array, arrival_times_sep, photon_number_per_emitter, expected_oscillations,std_dev,top_freq,std_dev2, ensemble_size):\n",
    "    freq_arrays_sep = []\n",
    "    for i in range(ensemble_size):\n",
    "        switching_arr = np.zeros((2,int(expected_oscillations)))\n",
    "        \n",
    "        switching_arr[0,:] = np.sort(np.random.uniform(0,total_time*1e12, size=int(expected_oscillations)))\n",
    "        switching_arr[1,:] = np.random.normal(top_freq,std_dev2, size=int(expected_oscillations)) \n",
    "        indices = np.searchsorted(switching_arr[0, :],  arrival_times_sep[i], side='right') \n",
    "        \n",
    "        freq_arr = np.zeros(photon_number_per_emitter[i])\n",
    "        # Draw from a Gaussian distribution for each center frequency\n",
    "        \n",
    "    \n",
    "        \n",
    "        for j in range(photon_number_per_emitter[i]):\n",
    "            # Get the center frequency corresponding to the index\n",
    "            index = indices[j]%int(expected_oscillations)\n",
    "         \n",
    "            center_frequency = switching_arr[1, index]\n",
    "            # Draw from a Gaussian distribution with center frequency as mean\n",
    "            #freq_arr[j] = np.random.normal(center_frequency, std_dev)\n",
    "            #or Lorenzen \n",
    "            freq_arr[j] = center_frequency + std_dev*np.random.standard_cauchy()\n",
    "            #if you want to use two narrow lines\n",
    "            #freq_arr[j] = center_frequency\n",
    "        freq_arrays_sep.append(freq_arr)\n",
    "   \n",
    "    combined_list = []\n",
    "    for time_list, freq_list in zip(arrival_times_sep, freq_arrays_sep):\n",
    "        combined_list.extend(zip(time_list, freq_list))\n",
    "\n",
    "    combined_list_sorted = sorted(combined_list, key=lambda x: x[0])\n",
    "\n",
    "    freq_array = [freq for time, freq in combined_list_sorted]\n",
    "\n",
    "    return freq_array ,  freq_arrays_sep\n",
    "\n",
    "\n",
    "def simulate_arrival_time_gamma(photons_per_emitter ,total_time,probability_per_bin,detector_resolution, ensemble_size):\n",
    "    arrival_times_sep = []\n",
    "    for i in range(ensemble_size):\n",
    "        arrival_times = np.random.gamma(shape=1, scale=1/probability_per_bin, size=int(int(photons_per_emitter[i])))\n",
    "        arrival_times = np.cumsum(arrival_times) *detector_resolution\n",
    "        arrival_times_sep.append(arrival_times)\n",
    "    \n",
    "    flattened_list = np.array([item for sublist in arrival_times_sep for item in sublist])\n",
    "    sorted_arrival_times = np.sort(flattened_list)\n",
    "    return sorted_arrival_times , arrival_times_sep\n",
    "    \n",
    "\n",
    "\n",
    "#writes stage positions in an exponential manner\n",
    "def exp_spacing_position(number_of_pos, final_pos, stage_position):\n",
    "    \n",
    "    x = final_pos**(1/number_of_pos)\n",
    "    \n",
    "    for i in range(0,number_of_pos+1):\n",
    "        new_pos = x**i\n",
    "        stage_position.append(new_pos)\n",
    "#writes stage positions in a linear manner\n",
    "def linear_spacing_position(number_of_pos, final_pos, stage_position):\n",
    "    x = final_pos/number_of_pos\n",
    "    for i in range(number_of_pos):\n",
    "        a = i\n",
    "        new_pos = x*a\n",
    "        stage_position.append(new_pos)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "efef6362",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Gaussian functions f(x) and g(x)\n",
    "def gaussian(x, A, mu, sigma):\n",
    "    return A * np.exp(-0.5 * ((x - mu) / sigma)**2)\n",
    "\n",
    "def lorenzian(x, x0, gamma, A):\n",
    "    return A * (gamma / ((x - x0) ** 2 + gamma ** 2) / np.pi)\n",
    "\n",
    "'''\n",
    "yet to see if both of these functions work the same in the curve fitting, they should \n",
    "'''\n",
    "#def gaussian(x, A, mu, sigma):\n",
    "  #  return A * np.exp(-(x - mu)**2 / (2 * sigma**2))\n",
    "\n",
    "\n",
    "def calculate_convolution_gaussian(top_freq, bot_freq,std_dev, plot = False):\n",
    "    A = 1\n",
    "    mu_f = 0\n",
    "    mu_g = np.abs(top_freq-bot_freq)\n",
    "\n",
    "    x_min = -5\n",
    "    x_max = 5\n",
    "    delta_x = .01\n",
    "    x_values = np.arange(x_min, x_max, delta_x)\n",
    "\n",
    "    # Compute the values of f(x) and g(x)\n",
    "    f_x = gaussian(x_values, A, mu_f, std_dev)\n",
    "    g_x = gaussian(x_values, A, mu_g, std_dev)\n",
    "    g_x_neg = gaussian(x_values, A, -1*mu_g, std_dev)\n",
    "    # Compute the cross-correlation\n",
    "    cross_corr_result = np.correlate(f_x, f_x, mode='same') * delta_x\n",
    "    dif_cross_corr_result = np.correlate(f_x, 2*f_x+g_x+g_x_neg, mode='same') * delta_x\n",
    "    \n",
    "\n",
    "    popt, pcov = curve_fit(gaussian, x_values, cross_corr_result/max(cross_corr_result), p0=[1, 0, 1])\n",
    "    dif_popt, dif_pcov = curve_fit(gaussian, x_values, dif_cross_corr_result/max(dif_cross_corr_result), p0=[1, 0, 1])\n",
    "    \n",
    "    # Extract parameters of the fitted Gaussian\n",
    "    A_fit, mu_fit, sigma_fit = popt\n",
    "    \n",
    "    dif_A_fit, dif_mu_fit, dif_sigma_fit = dif_popt\n",
    "\n",
    "    # Compute FWHM\n",
    "    FWHM1 = 2 * np.sqrt(2 * np.log(2)) * sigma_fit\n",
    "    dif_FWHM = 2 * np.sqrt(2 * np.log(2)) * dif_sigma_fit\n",
    "\n",
    "    # Compute standard deviation\n",
    "    std_deviation1 = sigma_fit\n",
    "    if plot:\n",
    "        # Plot the original cross-correlation and the fitted Gaussian\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.plot(x_values, cross_corr_result/max(cross_corr_result), label='Cross-correlation', color='blue')\n",
    "        plt.plot(x_values, dif_cross_corr_result/max(dif_cross_corr_result), label='dif_Cross-correlation', color='purple')\n",
    "        \n",
    "        plt.plot(x_values, gaussian(x_values, *popt), label='Fitted Gaussian', color='red', linestyle='--')\n",
    "        plt.plot(x_values, gaussian(x_values, *dif_popt), label='dif_Fitted Gaussian', color='green', linestyle='--')\n",
    "        plt.title('Cross-correlation and Fitted Gaussian')\n",
    "        plt.xlabel('x')\n",
    "        plt.ylabel('Cross-correlation')\n",
    "        plt.legend()\n",
    "        \n",
    "        plt.show()\n",
    "\n",
    "        print('% undiffused is',(100*(FWHM1/dif_FWHM)))\n",
    "    return ((FWHM1/dif_FWHM))\n",
    "   \n",
    "def calculate_convolution_lorentzian(top_freq, bot_freq, gamma, plot=False):\n",
    "    A = 1\n",
    "    mu_f = 0\n",
    "    mu_g = np.abs(top_freq - bot_freq)\n",
    "    print(f'{mu_g}')\n",
    "    x_min = -5\n",
    "    x_max = 5\n",
    "    delta_x = .001\n",
    "    x_values = np.arange(x_min, x_max, delta_x)\n",
    "    \n",
    "    # Compute the values of f(x) and g(x)\n",
    "    f_x = lorenzian(x_values, mu_f, gamma, A)\n",
    "    g_x = lorenzian(x_values, mu_g, gamma, A)\n",
    "    g_x_neg = lorenzian(x_values, -1 * mu_g, gamma, A)\n",
    "    \n",
    "    \n",
    "    # Compute the cross-correlation\n",
    "    cross_corr_result = np.correlate(f_x, f_x, mode='same') * delta_x\n",
    "    dif_cross_corr_result = np.correlate(f_x, 2 * f_x + g_x + g_x_neg, mode='same') * delta_x\n",
    "\n",
    "    popt, pcov = curve_fit(lorenzian, x_values, cross_corr_result / max(cross_corr_result), p0=[0, 1, 1])\n",
    "    dif_popt, dif_pcov = curve_fit(lorenzian, x_values, dif_cross_corr_result / max(dif_cross_corr_result), p0=[0, 1, 1])\n",
    "    \n",
    "    # Extract parameters of the fitted Lorentzian\n",
    "    x0_fit, gamma_fit, A_fit = popt\n",
    "    dif_x0_fit, dif_gamma_fit, dif_A_fit = dif_popt\n",
    "\n",
    "    # Compute FWHM\n",
    "    FWHM1 = 2 * gamma_fit\n",
    "    dif_FWHM = 2 * dif_gamma_fit\n",
    "\n",
    "    if plot:\n",
    "        # Plot the original cross-correlation and the fitted Lorentzian\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.plot(x_values, cross_corr_result / max(cross_corr_result), label='Cross-correlation', color='blue')\n",
    "        plt.plot(x_values, dif_cross_corr_result / max(dif_cross_corr_result), label='dif_Cross-correlation', color='purple')\n",
    "\n",
    "        plt.plot(x_values, lorenzian(x_values, *popt), label='Fitted Lorentzian', color='red', linestyle='--')\n",
    "        plt.plot(x_values, lorenzian(x_values, *dif_popt), label='dif_Fitted Lorentzian', color='green', linestyle='--')\n",
    "        plt.title('Cross-correlation and Fitted Lorentzian')\n",
    "        plt.xlabel('x')\n",
    "        plt.ylabel('Cross-correlation')\n",
    "        plt.legend()\n",
    "        plt.xlim(-2,2)\n",
    "        plt.show()\n",
    "      \n",
    "        print('% undiffused is', (100 * (FWHM1 / dif_FWHM)))\n",
    "    \n",
    "    return FWHM1 / dif_FWHM\n",
    "    \n",
    "\n",
    "def run_simulation(directory, top_freq, bot_freq, std_dev, ensamble_size, photons_per_emitter,total_time ,number_of_pos ,detector_resolution = 1e2,\n",
    "                   switching_time = 1e8):\n",
    "    pos_file_name = directory + os.sep +'posFile.pos'\n",
    "    pcfs_file_name = directory + os.sep +'position.pcfslog'\n",
    "    pos_file = open(pos_file_name,'w')\n",
    "    pcfs_log_file = open(pcfs_file_name, 'w')\n",
    "    PPS = int(ensamble_size*photons_per_emitter)\n",
    "    expected_oscillations = int(total_time*1e12/switching_time)\n",
    "    # Calculate coherence length\n",
    "    coherence_length_result = coherence_length(bot_freq, std_dev)\n",
    "    print(\"Coherence Length:\", coherence_length_result, \"nm\") \n",
    "    #choose center stage positions in nm as path length differences \n",
    "    stage_position = []\n",
    "    \n",
    "    final_pos = coherence_length_result #in nm. 1e8 is the largest possible stage pos but dont increase sim beyond 7e5 in practicality\n",
    "    linear_spacing_position(number_of_pos, final_pos,stage_position)\n",
    "    \n",
    "    counter = 0\n",
    "    for i in stage_position:\n",
    "        #photon_number = int(PPS*total_time)\n",
    "        photon_number_per_emitter =np.random.poisson(int(PPS*total_time),ensemble_size)\n",
    "        photon_number = np.sum(photon_number_per_emitter)\n",
    "        \n",
    "        projected_time_start = timing.time()\n",
    "        counter +=1\n",
    "        print(f'stage position {counter} completed')\n",
    "        file_name = f'pos {int(i)}'\n",
    "        \n",
    "          # Calculate probability of finding a photon in a detector bin\n",
    "        probability_per_bin = (PPS / 1e12) * detector_resolution\n",
    "        number_of_bins = total_time*1e12/detector_resolution\n",
    "        start1 = timing.time()\n",
    "        time_arr , arrival_times_sep = simulate_arrival_time_gamma(photon_number_per_emitter,total_time, probability_per_bin,detector_resolution, ensemble_size)\n",
    "        end1 = timing.time()\n",
    "        print(f'time to simulate arrival times {end1-start1}')\n",
    "\n",
    "\n",
    "        start4 = timing.time()\n",
    "        freq_array, freq_arr_sep = assign_gaussian_frequency_soft_switching_under_envelope(detector_resolution,probability_per_bin,total_time, time_arr, arrival_times_sep, photon_number_per_emitter, expected_oscillations,std_dev,top_freq,std_dev2, ensemble_size)\n",
    "     \n",
    "        end4 = timing.time()\n",
    "        print(f'time to assign freqq {end4-start4}')\n",
    "        center_stage_position = i\n",
    "        #amplitude in nm /2 this is from center to peak \n",
    "        dither_amplitude = 1200\n",
    "        #period in  picoseconds\n",
    "        dither_time_period =int(1e12)\n",
    "        time_between_stage_steps = 1e6\n",
    "        \n",
    "   \n",
    "        #all data for each photon stored in an array, first column is channel, second is arrival time, fourth is frequency, third is a place holder if the sim will expand to add relative time to a pulse\n",
    "        photon_arr = np.zeros((photon_number, 4))\n",
    "        #set the 4th column to be photon color\n",
    "        photon_arr[:,3]= freq_array\n",
    "        #set the first column to be channel 1\n",
    "        photon_arr[:,0] =1\n",
    "        photon_arr[:,1] = time_arr\n",
    "        #create dither waveform \n",
    "        #make sure the dither period is divisible by 4 to work with nice round numbers\n",
    "        dither_waveform = np.zeros(int(dither_time_period/time_between_stage_steps))\n",
    "\n",
    "        dither_waveform[:int(dither_time_period/(4*time_between_stage_steps))] = np.linspace(center_stage_position , dither_amplitude+center_stage_position,int(dither_time_period/(4*time_between_stage_steps)))\n",
    "        dither_waveform[int(dither_time_period/(4*time_between_stage_steps)):int(3*dither_time_period/(4*time_between_stage_steps))] = np.linspace(dither_amplitude+center_stage_position , center_stage_position-dither_amplitude, int(dither_time_period/(2*time_between_stage_steps)))\n",
    "        dither_waveform[int(3*dither_time_period/(4*time_between_stage_steps)):] = np.linspace(center_stage_position-dither_amplitude , center_stage_position,  int(dither_time_period/(4*time_between_stage_steps)))\n",
    "        #Find where we are in the dither given absolute time\n",
    "        relative_dither_time = photon_arr[:,1] % dither_time_period\n",
    "        stage_pos = np.zeros(photon_number)\n",
    "         # Convert relative_dither_time to indices directly\n",
    "        indices = (relative_dither_time / time_between_stage_steps).astype(int)\n",
    "        # Use array indexing to assign values to stage_pos\n",
    "        stage_pos = dither_waveform[indices]\n",
    "        #based on interference contstruct a probability of going to one detector or the other, this also serves to make the detectors anticorrelated in phase\n",
    "        p1 = .5 +.5*np.cos(4*np.pi*stage_pos[:]/photon_arr[:,3])\n",
    "      \n",
    "        random_number = np.random.rand(photon_number, 1)\n",
    "\n",
    "        start2 = timing.time()\n",
    "\n",
    "        # Reshape p1 array to match the shape of random_number\n",
    "        p1_reshaped = p1.reshape(-1, 1)\n",
    "\n",
    "        # Use vectorized comparison to create mask\n",
    "        mask = random_number > p1_reshaped\n",
    "\n",
    "        # Convert mask to boolean array\n",
    "        mask = np.squeeze(mask)\n",
    "\n",
    "        # Modify photon_arr in-place using boolean indexing\n",
    "        photon_arr[mask, 0] = 2\n",
    "\n",
    "        end2 = timing.time()\n",
    "        print(f'time to make photons array {end2 - start2}')\n",
    "\n",
    "        #write positions to file as nm\n",
    "        value = str(i*1e-6)\n",
    "\n",
    "        pos_file.write(value + \"\\n\")\n",
    "        pcfs_log_file.write(value + \"\\n\")\n",
    "        \n",
    "        photons_mimic = photon_arr[:,:2]\n",
    "        photons_mimic = photons_mimic.flatten()\n",
    "        \n",
    "        #write photons file in binary\n",
    "        fout = open(directory +os.sep + file_name + '.photons', 'wb')\n",
    "        \n",
    "        photons_mimic.astype(np.uint64).tofile(fout)\n",
    "        fout.close()\n",
    "        \n",
    "        projected_time_end = timing.time()\n",
    "        total_for_one_loop = projected_time_end - projected_time_start\n",
    "        total_time_proj = total_for_one_loop * number_of_pos\n",
    "        time_left = total_time_proj - total_for_one_loop*counter\n",
    "        print(f'total time to complete is {int(total_time_proj/60)}mins and the total time left is {int(time_left/60)}mins')\n",
    "        \n",
    "        \n",
    "        \n",
    "    pos_file.close() \n",
    "    pcfs_log_file.close()\n",
    "    \n",
    "def convert_wn_to_wl(reighliegh_wavelength,raman_wavenumber,linewidth_cm, freq_jump_cm):\n",
    "    raman_wavelength = 1e7/(1e7/reighliegh_wavelength-raman_wavenumber)\n",
    "    #cm -1 to nm conversion \n",
    "    #for single conversion s\n",
    "\n",
    "    raman_wavelength = 1e7/(1e7/reighliegh_wavelength-raman_wavenumber)\n",
    "\n",
    "    #compute the nm shift for inverse cm shifts\n",
    "    center_peak1 = raman_wavenumber\n",
    "    upper_end1 = center_peak1+linewidth_cm/2\n",
    "    lower_end1 = center_peak1-linewidth_cm/2\n",
    "    upper_nm1 = 1e7/(1e7/reighliegh_wavelength-upper_end1)\n",
    "    lower_nm1= 1e7/(1e7/reighliegh_wavelength-lower_end1)\n",
    "\n",
    "    #linewidth in nm \n",
    "    linewidth_nm = (upper_nm1-lower_nm1)/2\n",
    "\n",
    "    #compute the nm shift for inverse cm shifts\n",
    " \n",
    "    center_peak = raman_wavenumber\n",
    "    upper_end = center_peak+freq_jump_cm\n",
    "    lower_end = center_peak\n",
    "    upper_nm = 1e7/(1e7/reighliegh_wavelength-upper_end)\n",
    "    lower_nm = 1e7/(1e7/reighliegh_wavelength-lower_end)\n",
    "\n",
    "    #linewidth in nm \n",
    "    nm_shift = upper_nm-lower_nm\n",
    "\n",
    "    return (raman_wavelength, nm_shift, linewidth_nm)\n",
    "\n",
    "raman_wavelength, shift, linewidth = convert_wn_to_wl(reighliegh_wavelength = 633,raman_wavenumber = 810 ,linewidth_cm = 1.5, freq_jump_cm = 3)\n",
    "%run jupyter_photons_code_FI.ipynb   \n",
    "%run jupyter_pcfs_code_FI.ipynb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75686a51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.06678203136982575] 0.08903379855257754\n",
      "Directory already exists: /global/scratch/projects/co_utzatgroup/ccobbbruno/24_11_01/0.07nm_wavelength_difference\n",
      "Coherence Length: 1591868.0196410858 nm\n",
      "stage position 1 completed\n",
      "time to simulate arrival times 3.3408989906311035\n",
      "time to assign freqq 21.483259916305542\n",
      "time to make photons array 0.2057492733001709\n",
      "total time to complete is 4mins and the total time left is 4mins\n",
      "stage position 2 completed\n",
      "time to simulate arrival times 3.1262400150299072\n",
      "time to assign freqq 21.358173370361328\n",
      "time to make photons array 0.2219066619873047\n",
      "total time to complete is 4mins and the total time left is 3mins\n",
      "stage position 3 completed\n",
      "time to simulate arrival times 3.144486665725708\n",
      "time to assign freqq 22.52081322669983\n",
      "time to make photons array 0.2166123390197754\n",
      "total time to complete is 4mins and the total time left is 3mins\n",
      "stage position 4 completed\n",
      "time to simulate arrival times 3.2263195514678955\n",
      "time to assign freqq 22.89397382736206\n",
      "time to make photons array 0.22980046272277832\n",
      "total time to complete is 4mins and the total time left is 2mins\n",
      "stage position 5 completed\n",
      "time to simulate arrival times 3.3601431846618652\n",
      "time to assign freqq 23.648113489151\n",
      "time to make photons array 0.23157072067260742\n",
      "total time to complete is 5mins and the total time left is 2mins\n",
      "stage position 6 completed\n",
      "time to simulate arrival times 3.4290707111358643\n",
      "time to assign freqq 23.95001745223999\n",
      "time to make photons array 0.2163243293762207\n",
      "total time to complete is 12mins and the total time left is 5mins\n",
      "stage position 7 completed\n",
      "time to simulate arrival times 3.7133634090423584\n",
      "time to assign freqq 24.449650764465332\n",
      "time to make photons array 0.2186586856842041\n",
      "total time to complete is 5mins and the total time left is 1mins\n",
      "stage position 8 completed\n",
      "time to simulate arrival times 3.6201705932617188\n",
      "time to assign freqq 24.402859210968018\n",
      "time to make photons array 0.21507644653320312\n",
      "total time to complete is 10mins and the total time left is 2mins\n",
      "stage position 9 completed\n",
      "time to simulate arrival times 3.767677068710327\n",
      "time to assign freqq 24.181986570358276\n",
      "time to make photons array 0.21666502952575684\n",
      "total time to complete is 5mins and the total time left is 0mins\n",
      "stage position 10 completed\n",
      "time to simulate arrival times 3.7649292945861816\n",
      "time to assign freqq 24.45278811454773\n",
      "time to make photons array 0.21558427810668945\n",
      "total time to complete is 5mins and the total time left is 0mins\n",
      "['pos 0', 'sum_signal_pos 0', 'pos 159186', 'sum_signal_pos 159186', 'pos 318373', 'sum_signal_pos 318373', 'sum_signal_pos 477560', 'pos 477560', 'pos 636747', 'sum_signal_pos 636747', 'pos 795934', 'sum_signal_pos 795934', 'pos 955120', 'sum_signal_pos 955120', 'pos 1114307', 'sum_signal_pos 1114307', 'pos 1273494', 'sum_signal_pos 1273494', 'sum_signal_pos 1432681', 'pos 1432681']\n",
      "========================================\n",
      "Photon class created\n",
      "========================================\n",
      "========================================\n",
      "Photon class created\n",
      "========================================\n",
      "========================================\n",
      "Photon class created\n",
      "========================================\n",
      "========================================\n",
      "Photon class created\n",
      "========================================\n",
      "========================================\n",
      "Photon class created\n",
      "========================================\n",
      "========================================\n",
      "Photon class created\n",
      "========================================\n",
      "========================================\n",
      "Photon class created\n",
      "========================================\n",
      "========================================\n",
      "Photon class created\n",
      "========================================\n",
      "========================================\n",
      "Photon class created\n",
      "========================================\n",
      "========================================\n",
      "Photon class created\n",
      "========================================\n",
      "========================================\n",
      "Photon class created\n",
      "========================================\n",
      "========================================\n",
      "Photon class created\n",
      "========================================\n",
      "========================================\n",
      "Photon class created\n",
      "========================================\n",
      "========================================\n",
      "Photon class created\n",
      "========================================\n",
      "========================================\n",
      "Photon class created\n",
      "========================================\n",
      "========================================\n",
      "Photon class created\n",
      "========================================\n",
      "========================================\n",
      "Photon class created\n",
      "========================================\n",
      "========================================\n",
      "Photon class created\n",
      "========================================\n",
      "========================================\n",
      "Photon class created\n",
      "========================================\n",
      "========================================\n",
      "Photon class created\n",
      "========================================\n",
      "Total time elapsed to create PCFS class is 0.008312 s\n",
      "['pos 0', 'sum_signal_pos 0', 'pos 159186', 'sum_signal_pos 159186', 'pos 318373', 'sum_signal_pos 318373', 'sum_signal_pos 477560', 'pos 477560', 'pos 636747', 'sum_signal_pos 636747', 'pos 795934', 'sum_signal_pos 795934', 'pos 955120', 'sum_signal_pos 955120', 'pos 1114307', 'sum_signal_pos 1114307', 'pos 1273494', 'sum_signal_pos 1273494', 'sum_signal_pos 1432681', 'pos 1432681']\n",
      "['pos 0', 'sum_signal_pos 0', 'pos 159186', 'sum_signal_pos 159186', 'pos 318373', 'sum_signal_pos 318373', 'sum_signal_pos 477560', 'pos 477560', 'pos 636747', 'sum_signal_pos 636747', 'pos 795934', 'sum_signal_pos 795934', 'pos 955120', 'sum_signal_pos 955120', 'pos 1114307', 'sum_signal_pos 1114307', 'pos 1273494', 'sum_signal_pos 1273494', 'sum_signal_pos 1432681', 'pos 1432681']\n",
      "Total time elapsed to get sum signal of photons is 0.000690 s\n",
      "['pos 0', 'sum_signal_pos 0', 'pos 159186', 'sum_signal_pos 159186', 'pos 318373', 'sum_signal_pos 318373', 'sum_signal_pos 477560', 'pos 477560', 'pos 636747', 'sum_signal_pos 636747', 'pos 795934', 'sum_signal_pos 795934', 'pos 955120', 'sum_signal_pos 955120', 'pos 1114307', 'sum_signal_pos 1114307', 'pos 1273494', 'sum_signal_pos 1273494', 'sum_signal_pos 1432681', 'pos 1432681']\n",
      "Correlating data...\n",
      "\n",
      "Done\n",
      "\n",
      "Time elapsed during correlating is 8.109889 s\n",
      "Total time elapsed is 10.039224 s\n",
      "==============================\n",
      "total time to complete is 3mins and the total time left is 3mins\n",
      "Correlating data...\n",
      "\n",
      "Done\n",
      "\n",
      "Time elapsed during correlating is 0.979244 s\n",
      "Total time elapsed is 1.128556 s\n",
      "==============================\n",
      "total time to complete is 0mins and the total time left is 0mins\n",
      "Correlating data...\n",
      "\n",
      "Done\n",
      "\n",
      "Time elapsed during correlating is 8.096267 s\n",
      "Total time elapsed is 9.531080 s\n",
      "==============================\n",
      "total time to complete is 3mins and the total time left is 2mins\n",
      "Correlating data...\n",
      "\n",
      "Done\n",
      "\n",
      "Time elapsed during correlating is 0.969802 s\n",
      "Total time elapsed is 1.109386 s\n",
      "==============================\n",
      "total time to complete is 0mins and the total time left is 0mins\n",
      "Correlating data...\n",
      "\n",
      "Done\n",
      "\n",
      "Time elapsed during correlating is 8.376089 s\n",
      "Total time elapsed is 9.813828 s\n",
      "==============================\n",
      "total time to complete is 3mins and the total time left is 2mins\n",
      "Correlating data...\n",
      "\n",
      "Done\n",
      "\n",
      "Time elapsed during correlating is 0.967132 s\n",
      "Total time elapsed is 1.109005 s\n",
      "==============================\n",
      "total time to complete is 0mins and the total time left is 0mins\n",
      "Correlating data...\n",
      "\n",
      "Done\n",
      "\n",
      "Time elapsed during correlating is 0.965030 s\n",
      "Total time elapsed is 1.102438 s\n",
      "==============================\n",
      "total time to complete is 0mins and the total time left is 0mins\n",
      "Correlating data...\n",
      "\n",
      "Done\n",
      "\n",
      "Time elapsed during correlating is 8.403249 s\n",
      "Total time elapsed is 9.858316 s\n",
      "==============================\n",
      "total time to complete is 3mins and the total time left is 1mins\n",
      "Correlating data...\n",
      "\n",
      "Done\n",
      "\n",
      "Time elapsed during correlating is 8.409421 s\n",
      "Total time elapsed is 10.332806 s\n",
      "==============================\n",
      "total time to complete is 3mins and the total time left is 1mins\n",
      "Correlating data...\n",
      "\n",
      "Done\n",
      "\n",
      "Time elapsed during correlating is 0.968596 s\n",
      "Total time elapsed is 1.113536 s\n",
      "==============================\n",
      "total time to complete is 0mins and the total time left is 0mins\n",
      "Correlating data...\n",
      "\n",
      "Done\n",
      "\n",
      "Time elapsed during correlating is 8.405379 s\n",
      "Total time elapsed is 9.850692 s\n",
      "==============================\n",
      "total time to complete is 3mins and the total time left is 1mins\n",
      "Correlating data...\n",
      "\n",
      "Done\n",
      "\n",
      "Time elapsed during correlating is 0.969953 s\n",
      "Total time elapsed is 1.107336 s\n",
      "==============================\n",
      "total time to complete is 0mins and the total time left is 0mins\n",
      "Correlating data...\n",
      "\n",
      "Done\n",
      "\n",
      "Time elapsed during correlating is 8.434540 s\n",
      "Total time elapsed is 9.879591 s\n",
      "==============================\n",
      "total time to complete is 3mins and the total time left is 1mins\n",
      "Correlating data...\n",
      "\n",
      "Done\n",
      "\n",
      "Time elapsed during correlating is 0.967681 s\n",
      "Total time elapsed is 1.110640 s\n",
      "==============================\n",
      "total time to complete is 0mins and the total time left is 0mins\n",
      "Correlating data...\n",
      "\n",
      "Done\n",
      "\n",
      "Time elapsed during correlating is 8.429628 s\n",
      "Total time elapsed is 9.881416 s\n",
      "==============================\n",
      "total time to complete is 3mins and the total time left is 0mins\n",
      "Correlating data...\n",
      "\n",
      "Done\n",
      "\n",
      "Time elapsed during correlating is 0.967804 s\n",
      "Total time elapsed is 1.531950 s\n",
      "==============================\n",
      "total time to complete is 0mins and the total time left is 0mins\n",
      "Correlating data...\n",
      "\n",
      "Done\n",
      "\n",
      "Time elapsed during correlating is 8.428117 s\n",
      "Total time elapsed is 9.874514 s\n",
      "==============================\n",
      "total time to complete is 3mins and the total time left is 0mins\n",
      "Correlating data...\n",
      "\n",
      "Done\n",
      "\n",
      "Time elapsed during correlating is 0.967438 s\n",
      "Total time elapsed is 1.106289 s\n",
      "==============================\n",
      "total time to complete is 0mins and the total time left is 0mins\n",
      "Correlating data...\n",
      "\n",
      "Done\n",
      "\n",
      "Time elapsed during correlating is 0.973443 s\n",
      "Total time elapsed is 1.110417 s\n",
      "==============================\n",
      "total time to complete is 0mins and the total time left is 0mins\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "primary_directory = '/global/scratch/projects/co_utzatgroup/ccobbbruno/24_11_01/'\n",
    "\n",
    "\n",
    "\n",
    "ensemble_size = 4\n",
    "#photons per emitter per second\n",
    "photons_per_emitter =1e5\n",
    "# Define time of simulation in s\n",
    "total_time =int(10)\n",
    "detector_resolution = 1e2\n",
    "#the number of cycles you expect the frequency to go through in ps\n",
    "switching_time = 1e9\n",
    "number_of_pos = 10\n",
    "\n",
    "raman_wavelength, shift, linewidth = convert_wn_to_wl(reighliegh_wavelength = 633, raman_wavenumber = 810 ,linewidth_cm = 4, freq_jump_cm = 1.5)\n",
    "_, _, std_dev2 = convert_wn_to_wl(reighliegh_wavelength = 633, raman_wavenumber = 810 ,linewidth_cm =8, freq_jump_cm = 8)\n",
    "dif_array = [shift]\n",
    "\n",
    "collective_fwhm_arr = []\n",
    "std_dev = linewidth\n",
    "top_freq = raman_wavelength\n",
    "print(dif_array,std_dev)\n",
    "pcfs_instances = {}\n",
    "for dif in dif_array:\n",
    "    directory = os.path.join(primary_directory, f'{dif:.2f}nm_wavelength_difference')\n",
    "    \n",
    "    # Check if the directory already exists\n",
    "    if not os.path.exists(directory):\n",
    "        # If not, create the directory\n",
    "        os.makedirs(directory)\n",
    "        print(f\"Created directory: {directory}\")\n",
    "    else:\n",
    "        print(f\"Directory already exists: {directory}\")\n",
    "        \n",
    "    \n",
    "    bot_freq = float(raman_wavelength + dif)\n",
    "    \n",
    "    run_simulation(directory, top_freq, bot_freq, std_dev, ensemble_size, photons_per_emitter,total_time ,number_of_pos)\n",
    "    \n",
    "    pcfs_instance_name = f\"pcfs_{dif:.2f}\"\n",
    "    pcfs_instances[pcfs_instance_name] = PCFS(directory, 2, simulation=True)\n",
    "    pcfs_instances[pcfs_instance_name].get_intensity_correlations((1e1, 1e11), 3)\n",
    "    pcfs_instances[pcfs_instance_name].get_blinking_corrected_PCFS()\n",
    "    pcfs_instances[pcfs_instance_name].get_splev_mirror_spec_corr(0, 0, fit_interferogram = True)\n",
    "    pcfs_instances[pcfs_instance_name].plot_spectral_diffusion([1e2, 1e6, 1e9], -4)\n",
    "    pcfs_instances[pcfs_instance_name].plot_splev_spec_corr([1e7, 1e9], (-2.5, 2.5))\n",
    "    #for i,tau in enumerate(pcfs_instances[pcfs_instance_name].tau):\n",
    "       # plt.plot(pcfs_instances[pcfs_instance_name].blinking_corrected_PCFS_interferogram[i, :])\n",
    "       # plt.show()\n",
    "        \n",
    "    calculate_convolution_lorentzian(top_freq, bot_freq,std_dev, plot = True)\n",
    "\n",
    "    fwhm_arr = []\n",
    "    for i in range(len(pcfs_instances[pcfs_instance_name].tau)):\n",
    "        y = pcfs_instances[pcfs_instance_name].splev_spec_corr['spectral_corr'][i,:]/max(pcfs_instances[pcfs_instance_name].splev_spec_corr['spectral_corr'][i,:])\n",
    "        x = pcfs_instances[pcfs_instance_name].splev_spec_corr['zeta']\n",
    "        try:\n",
    "            params, covariance = curve_fit(lorenzian, x, y)\n",
    "        except RuntimeError:\n",
    "            fwhm_arr.append(0)\n",
    "        else:\n",
    "            #for lorenzian\n",
    "            fwhm = 2 * params[1] \n",
    "            #for gaussian\n",
    "            #fwhm = 2 * np.sqrt(2 * np.log(2)) * params[2]\n",
    "            fwhm_arr.append(fwhm)\n",
    "            #plt.plot(x, y, 'bo', label='Data')\n",
    "            #plt.plot(x, lorenzian(x, *params), 'r-', label='Fit')\n",
    "            #plt.legend()\n",
    "\n",
    "           # plt.show()\n",
    "\n",
    "    plt.scatter(pcfs_instances[pcfs_instance_name].tau,fwhm_arr, label='Scatter Plot on Log Scales')\n",
    "    plt.xscale('log')\n",
    "    #plt.xlim(1e4,1e11)\n",
    "    plt.ylim(.5,5)\n",
    "    plt.show()\n",
    "    \n",
    "    print(bot_freq)\n",
    "    print(top_freq)\n",
    "    total_end = timing.time()\n",
    "    #print(f'total run time: {total_end-total_start}')\n",
    "    collective_fwhm_arr.append(fwhm_arr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3cedef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Create a figure with two subplots\n",
    "fig, axs = plt.subplots(3, 1, figsize=(10, 10))\n",
    "\n",
    "# Generate x values for the first subplot\n",
    "x = np.linspace(pcfs_instances[pcfs_instance_name].mirror_stage_positions[0], \n",
    "                pcfs_instances[pcfs_instance_name].mirror_stage_positions[-1], \n",
    "                len(pcfs_instances[pcfs_instance_name].mirror_PCFS_interferogram[1, :]))\n",
    "\n",
    "# First subplot\n",
    "for i, tau in enumerate(pcfs_instances[pcfs_instance_name].tau):\n",
    "    if 40 < i <50 and i % 2 == 0:\n",
    "        axs[0].plot(x, \n",
    "                    pcfs_instances[pcfs_instance_name].mirror_PCFS_interferogram[i, :] / max(pcfs_instances[pcfs_instance_name].mirror_PCFS_interferogram[i, :]), \n",
    "                    label=f'tau = {pcfs_instances[pcfs_instance_name].tau[i] / 1e6} us')\n",
    "axs[0].set_xlabel('mm')\n",
    "axs[0].set_ylabel('Normalized Interferogram')\n",
    "axs[0].legend()\n",
    "axs[0].set_title('Fitted PCFS Interferogram')\n",
    "\n",
    "# Second subplot\n",
    "for i, tau in enumerate(pcfs_instances[pcfs_instance_name].tau):\n",
    "    if 40 < i < 50 and i % 2 == 0:\n",
    "        axs[1].plot(pcfs_instances[pcfs_instance_name].stage_positions, \n",
    "                    pcfs_instances[pcfs_instance_name].blinking_corrected_PCFS_interferogram[i, :], \n",
    "                    label=f'tau = {pcfs_instances[pcfs_instance_name].tau[i] / 1e6} us')\n",
    "axs[1].set_xlabel('mm')\n",
    "axs[1].set_ylabel('Blinking Corrected Interferogram')\n",
    "axs[1].legend()\n",
    "axs[1].set_title('Blinking Corrected PCFS Interferogram')\n",
    "\n",
    "\n",
    "# Second subplot\n",
    "for i, tau in enumerate(pcfs_instances[pcfs_instance_name].tau):\n",
    "    if 40 < i < 50 and i % 2 == 0:\n",
    "        axs[2].plot(pcfs_instances[pcfs_instance_name].splev_spec_corr['zeta'], \n",
    "                    pcfs_instances[pcfs_instance_name].splev_spec_corr['spectral_corr'][i, :]/max(pcfs_instances[pcfs_instance_name].splev_spec_corr['spectral_corr'][i, :]), \n",
    "                    label=f'tau = {pcfs_instances[pcfs_instance_name].tau[i] / 1e6} us')\n",
    "axs[2].set_xlabel('meV')\n",
    "axs[2].set_ylabel('spectral corrleation')\n",
    "axs[2].set_xlim(-1,1)\n",
    "axs[2].legend()\n",
    "axs[2].set_title('spectral correlation')\n",
    "\n",
    "# Adjust layout to prevent overlap\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08dbe839",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Create a figure with two subplots\n",
    "fig, axs = plt.subplots(3, 1, figsize=(10, 10))\n",
    "\n",
    "# Generate x values for the first subplot\n",
    "x = np.linspace(pcfs_instances[pcfs_instance_name].mirror_stage_positions[0], \n",
    "                pcfs_instances[pcfs_instance_name].mirror_stage_positions[-1], \n",
    "                len(pcfs_instances[pcfs_instance_name].mirror_PCFS_interferogram[1, :]))\n",
    "\n",
    "# First subplot\n",
    "for i, tau in enumerate(pcfs_instances[pcfs_instance_name].tau):\n",
    "    if 50 < i < 60 and i % 2 == 0:\n",
    "        axs[0].plot(x, \n",
    "                    pcfs_instances[pcfs_instance_name].mirror_PCFS_interferogram[i, :] / max(pcfs_instances[pcfs_instance_name].mirror_PCFS_interferogram[i, :]), \n",
    "                    label=f'tau = {pcfs_instances[pcfs_instance_name].tau[i] / 1e6} us')\n",
    "axs[0].set_xlabel('mm')\n",
    "axs[0].set_ylabel('Normalized Interferogram')\n",
    "axs[0].legend()\n",
    "axs[0].set_title('Fitted PCFS Interferogram')\n",
    "\n",
    "# Second subplot\n",
    "for i, tau in enumerate(pcfs_instances[pcfs_instance_name].tau):\n",
    "    if 50 < i < 60 and i % 2 == 0:\n",
    "        axs[1].plot(pcfs_instances[pcfs_instance_name].stage_positions, \n",
    "                    pcfs_instances[pcfs_instance_name].blinking_corrected_PCFS_interferogram[i, :], \n",
    "                    label=f'tau = {pcfs_instances[pcfs_instance_name].tau[i] / 1e6} us')\n",
    "axs[1].set_xlabel('mm')\n",
    "axs[1].set_ylabel('Blinking Corrected Interferogram')\n",
    "axs[1].legend()\n",
    "axs[1].set_title('Blinking Corrected PCFS Interferogram')\n",
    "\n",
    "\n",
    "# Second subplot\n",
    "for i, tau in enumerate(pcfs_instances[pcfs_instance_name].tau):\n",
    "    if 50 < i < 60 and i % 2 == 0:\n",
    "        axs[2].plot(pcfs_instances[pcfs_instance_name].splev_spec_corr['zeta'], \n",
    "                    pcfs_instances[pcfs_instance_name].splev_spec_corr['spectral_corr'][i, :]/max(pcfs_instances[pcfs_instance_name].splev_spec_corr['spectral_corr'][i, :]), \n",
    "                    label=f'tau = {pcfs_instances[pcfs_instance_name].tau[i] / 1e6} us')\n",
    "axs[2].set_xlabel('meV')\n",
    "axs[2].set_ylabel('spectral corrleation')\n",
    "axs[2].set_xlim(-1,1)\n",
    "axs[2].legend()\n",
    "axs[2].set_title('spectral correlation')\n",
    "\n",
    "# Adjust layout to prevent overlap\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c5265d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Create a figure with two subplots\n",
    "fig, axs = plt.subplots(3, 1, figsize=(10, 10))\n",
    "\n",
    "# Generate x values for the first subplot\n",
    "x = np.linspace(pcfs_instances[pcfs_instance_name].mirror_stage_positions[0], \n",
    "                pcfs_instances[pcfs_instance_name].mirror_stage_positions[-1], \n",
    "                len(pcfs_instances[pcfs_instance_name].mirror_PCFS_interferogram[1, :]))\n",
    "\n",
    "# First subplot\n",
    "for i, tau in enumerate(pcfs_instances[pcfs_instance_name].tau):\n",
    "    if 60 < i < 70 and i % 2 == 0:\n",
    "        axs[0].plot(x, \n",
    "                    pcfs_instances[pcfs_instance_name].mirror_PCFS_interferogram[i, :] / max(pcfs_instances[pcfs_instance_name].mirror_PCFS_interferogram[i, :]), \n",
    "                    label=f'tau = {pcfs_instances[pcfs_instance_name].tau[i] / 1e6} us')\n",
    "axs[0].set_xlabel('mm')\n",
    "axs[0].set_ylabel('Normalized Interferogram')\n",
    "axs[0].legend()\n",
    "axs[0].set_title('Fitted PCFS Interferogram')\n",
    "\n",
    "# Second subplot\n",
    "for i, tau in enumerate(pcfs_instances[pcfs_instance_name].tau):\n",
    "    if 60 < i < 70 and i % 2 == 0:\n",
    "        axs[1].plot(pcfs_instances[pcfs_instance_name].stage_positions, \n",
    "                    pcfs_instances[pcfs_instance_name].blinking_corrected_PCFS_interferogram[i, :], \n",
    "                    label=f'tau = {pcfs_instances[pcfs_instance_name].tau[i] / 1e6} us')\n",
    "axs[1].set_xlabel('mm')\n",
    "axs[1].set_ylabel('Blinking Corrected Interferogram')\n",
    "axs[1].legend()\n",
    "axs[1].set_title('Blinking Corrected PCFS Interferogram')\n",
    "\n",
    "\n",
    "# Second subplot\n",
    "for i, tau in enumerate(pcfs_instances[pcfs_instance_name].tau):\n",
    "    if 60 < i < 70 and i % 2 == 0:\n",
    "        axs[2].plot(pcfs_instances[pcfs_instance_name].splev_spec_corr['zeta'], \n",
    "                    pcfs_instances[pcfs_instance_name].splev_spec_corr['spectral_corr'][i, :]/max(pcfs_instances[pcfs_instance_name].splev_spec_corr['spectral_corr'][i, :]), \n",
    "                    label=f'tau = {pcfs_instances[pcfs_instance_name].tau[i] / 1e6} us')\n",
    "axs[2].set_xlabel('meV')\n",
    "axs[2].set_ylabel('spectral corrleation')\n",
    "axs[2].set_xlim(-1,1)\n",
    "axs[2].legend()\n",
    "axs[2].set_title('spectral correlation')\n",
    "\n",
    "# Adjust layout to prevent overlap\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "clear_output() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb8d627c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fwhm_norm = fwhm_arr/fwhm_arr[85]\n",
    "\n",
    "\n",
    "plt.scatter(pcfs_instances[pcfs_instance_name].tau,fwhm_norm, label='Scatter Plot on Log Scales')\n",
    "plt.xscale('log')\n",
    "#plt.xlim(1e4,1e11)\n",
    "plt.ylim(0,4)\n",
    "plt.show()\n",
    "clear_output() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "373c2016",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run jupyter_photons_code_FI.ipynb   \n",
    "%run jupyter_pcfs_code_FI.ipynb\n",
    "\n",
    "primary_directory = '/global/scratch/projects/co_utzatgroup/ccobbbruno/24_05_20_fitting_interferogram_test/'\n",
    "\n",
    "\n",
    "\n",
    "ensamble_size = 1\n",
    "#photons per emitter per second\n",
    "photons_per_emitter =1e5\n",
    "# Define time of simulation in s\n",
    "total_time =int(1)\n",
    "detector_resolution = 1e2\n",
    "#the number of cycles you expect the frequency to go through in ps\n",
    "switching_time = 1e8\n",
    "number_of_pos = 50\n",
    "\n",
    "raman_wavelength, shift, linewidth = convert_wn_to_wl(reighliegh_wavelength = 633, raman_wavenumber = 810 ,linewidth_cm = 1.5, freq_jump_cm = 1.5)\n",
    "dif_array = [shift]\n",
    "\n",
    "collective_fwhm_arr = []\n",
    "std_dev = linewidth\n",
    "top_freq = raman_wavelength\n",
    "print(dif_array,std_dev)\n",
    "pcfs_instances = {}\n",
    "for dif in dif_array:\n",
    "    directory = os.path.join(primary_directory, f'{dif:.2f}nm_wavelength_difference')\n",
    "    \n",
    "    # Check if the directory already exists\n",
    "    if not os.path.exists(directory):\n",
    "        # If not, create the directory\n",
    "        os.makedirs(directory)\n",
    "        print(f\"Created directory: {directory}\")\n",
    "    else:\n",
    "        print(f\"Directory already exists: {directory}\")\n",
    "        \n",
    "    \n",
    "    bot_freq = float(raman_wavelength + dif)\n",
    "    \n",
    "    run_simulation(directory, top_freq, bot_freq, std_dev, ensamble_size, photons_per_emitter,total_time ,50)\n",
    "    \n",
    "    pcfs_instance_name = f\"pcfs_{dif:.2f}\"\n",
    "    pcfs_instances[pcfs_instance_name] = PCFS(directory, 2, simulation=True)\n",
    "    pcfs_instances[pcfs_instance_name].get_intensity_correlations((1e1, 1e11), 3)\n",
    "    pcfs_instances[pcfs_instance_name].get_blinking_corrected_PCFS()\n",
    "    pcfs_instances[pcfs_instance_name].get_splev_mirror_spec_corr(0, 0, fit_interferogram = False)\n",
    "    pcfs_instances[pcfs_instance_name].plot_spectral_diffusion([1e2, 1e6, 1e9], -4)\n",
    "    pcfs_instances[pcfs_instance_name].plot_splev_spec_corr([1e7, 1e9], (-2.5, 2.5))\n",
    "    for i,tau in enumerate(pcfs_instances[pcfs_instance_name].tau):\n",
    "        plt.plot(pcfs_instances[pcfs_instance_name].blinking_corrected_PCFS_interferogram[i, :])\n",
    "        plt.show()\n",
    "        \n",
    "    calculate_convolution_lorentzian(top_freq, bot_freq,std_dev, plot = True)\n",
    "\n",
    "    fwhm_arr = []\n",
    "    for i in range(len(pcfs_instances[pcfs_instance_name].tau)):\n",
    "        y = pcfs_instances[pcfs_instance_name].splev_spec_corr['spectral_corr'][i,:]/max(pcfs_instances[pcfs_instance_name].splev_spec_corr['spectral_corr'][i,:])\n",
    "        x = pcfs_instances[pcfs_instance_name].splev_spec_corr['zeta']\n",
    "        try:\n",
    "            params, covariance = curve_fit(lorenzian, x, y)\n",
    "        except RuntimeError:\n",
    "            fwhm_arr.append(0)\n",
    "        else:\n",
    "            #for lorenzian\n",
    "            fwhm = 2 * params[1] \n",
    "            #for gaussian\n",
    "            #fwhm = 2 * np.sqrt(2 * np.log(2)) * params[2]\n",
    "            fwhm_arr.append(fwhm)\n",
    "            #plt.plot(x, y, 'bo', label='Data')\n",
    "            #plt.plot(x, lorenzian(x, *params), 'r-', label='Fit')\n",
    "            #plt.legend()\n",
    "\n",
    "           # plt.show()\n",
    "\n",
    "    plt.scatter(pcfs_instances[pcfs_instance_name].tau,fwhm_arr, label='Scatter Plot on Log Scales')\n",
    "    plt.xscale('log')\n",
    "    #plt.xlim(1e4,1e11)\n",
    "    #plt.ylim(.5,1.1)\n",
    "    plt.show()\n",
    "    \n",
    "    print(bot_freq)\n",
    "    print(top_freq)\n",
    "    total_end = timing.time()\n",
    "    #print(f'total run time: {total_end-total_start}')\n",
    "    collective_fwhm_arr.append(fwhm_arr)\n",
    "clear_output() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d96a7bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "fwhm_norm = fwhm_arr/fwhm_arr[85]\n",
    "\n",
    "\n",
    "plt.scatter(pcfs_instances[pcfs_instance_name].tau,fwhm_norm, label='Scatter Plot on Log Scales')\n",
    "plt.xscale('log')\n",
    "#plt.xlim(1e4,1e11)\n",
    "plt.ylim(.7,1.2)\n",
    "\n",
    "plt.show()\n",
    "clear_output() "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
